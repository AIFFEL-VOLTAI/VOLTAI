{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evalutaion notebook codes\n",
    "임의로 문장 템플릿을 생성하여 llm answer의 value들을 넣어서 만든 문장을 비교하여 평가하는 코드입니다.  \n",
    "`question1` 과 `question2`에 대해서만 진행했습니다.  \n",
    "`question3` 와 `questino4`의 경우 수정될 수 있어 추후 진행하겠습니다. (금방할 수 있습니다)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install rouge-score\n",
    "# !pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from langchain_core.vectorstores.base import VectorStoreRetriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_teddynote.messages import messages_to_history\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "# from langchain_teddynote.evaluator import GroundednessChecker\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import random_uuid\n",
    "\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from metrics.metric_eval import evaluate_all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env 파일 로드\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "# API 키 가져오기\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# LangSmith 추적 기능을 활성화합니다. (선택적)\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Multi-agent Collaboration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_question(question_path:str=\"./config/questions/250115-SY-question.yaml\"):\n",
    "    with open(question_path, 'r') as file:\n",
    "        questions = yaml.safe_load(file)\n",
    "    \n",
    "    question_list = []\n",
    "    for i in range(1, 5):\n",
    "        if i == 3 or i == 4:\n",
    "           temp_question = f\"\"\"\n",
    "{questions[\"main_question\"]}{questions[f\"add_question{i}\"]}\n",
    "{json.dumps(questions[f\"example{i}\"], ensure_ascii=False, indent=4)}\n",
    "\"\"\" \n",
    "        else: \n",
    "            temp_question = f\"\"\"\n",
    "{questions[\"main_question\"]}\n",
    "{json.dumps(questions[f\"example{i}\"], ensure_ascii=False, indent=4)}\n",
    "\"\"\"\n",
    "\n",
    "        question_list.append(temp_question)        \n",
    "\n",
    "    return question_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = load_question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Below are instructions for filling out items by referring to the examples.\n",
      "The values shown to the right of the colon (\":\") are examples;\n",
      "please delete them after reviewing and rewrite them with the values found in the PDF.\n",
      "If any item is not mentioned in the PDF, do not remove it—write \"None.\"\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"CAM (Cathode Active Material)\": {\n",
      "            \"Stoichiometry information\": {\n",
      "                \"NCM-622\": {\n",
      "                    \"Li ratio\": \"1\",\n",
      "                    \"Ni ratio\": \"0.6\",\n",
      "                    \"Co ratio\": \"0.2\",\n",
      "                    \"Mn ratio\": \"0.2\",\n",
      "                    \"O ratio\": \"2\"\n",
      "                },\n",
      "                \"ZrO2-NCM-622 (Z622)\": {\n",
      "                    \"Li ratio\": \"0.98\",\n",
      "                    \"Ni ratio\": \"0.6\",\n",
      "                    \"Co ratio\": \"0.2\",\n",
      "                    \"Mn ratio\": \"0.2\",\n",
      "                    \"O ratio\": \"2\"\n",
      "                }\n",
      "            },\n",
      "            \"Whether or not commercial NCM was used for each sample (Stoichiometry information in order)\": [\n",
      "                \"yes\",\n",
      "                \"no\"\n",
      "            ],\n",
      "            \"Lithium source\": \"LiOH\",\n",
      "            \"Synthesis method\": \"co-precipitation\",\n",
      "            \"Describe the crystallization method, such as Hydrothermal, Sintering, or any other technique used during the process.\": \"Hydrothermal\",\n",
      "            \"What is the Crystallization final temperature in degree of Celcius used in the process? (e.g., calcination or sintering) mentioned for the crystallization stage.\": \"100\",\n",
      "            \"What is the time duration for the final crystallization process, including any calcination or sintering stages? Specify the hours.\": \"12\",\n",
      "            \"Doping\": \"Zr4+\",\n",
      "            \"Coating\": \"ZrO2\",\n",
      "            \"Additional treatment\": \"None\"\n",
      "        }\n",
      "    }\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(question_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_file(file_folder: str, file_name: str) -> VectorStoreRetriever:\n",
    "    \"\"\"문서를 청크 단위로 분할하고 임베딩 모델(text-embedding-ada-002)을 통해 임베딩하여 vector store에 저장합니다. 이후 vector store를 기반으로 검색하는 객체를 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        file (str): pdf 문서 경로\n",
    "\n",
    "    Returns:\n",
    "        VectorStoreRetriever: 검색기\n",
    "    \"\"\"\n",
    "    ## 긴 텍스트를 작은 청크로 나누는 데 사용되는 클래스\n",
    "    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=500,         ## 최대 청크 길이 정의\n",
    "        chunk_overlap=100,      ## 청크 간 겹침 길이 정의\n",
    "        separators=[\"\\n\\n\"]     ## 텍스트를 나눌 때 사용할 구분자를 지정 (문단)\n",
    "    )\n",
    "\n",
    "    ## PDF 파일 불러오기\n",
    "    loader = PyPDFLoader(f\"{file_folder}/{file_name}.pdf\")\n",
    "    docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "    ## Embedding 생성 및 vector store에 저장\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_store = FAISS.from_documents(\n",
    "        documents=docs,         ## 벡터 저장소에 추가할 문서 리스트\n",
    "        embedding=embeddings    ## 사용할 임베딩 함수\n",
    "    )\n",
    "\n",
    "    ## 검색기로 변환: 현재 벡터 저장소를 기반으로 VectorStoreRetriever 객체를 생성하는 기능을 제공\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",    ## 어떻게 검색할 것인지? default가 유사도\n",
    "        search_kwargs={\"k\": 10}\n",
    "    )\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### graph.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GraphState 상태 정의\n",
    "class GraphState(TypedDict):\n",
    "    question: Annotated[str, \"Question\"]  # 질문\n",
    "    context: Annotated[str, \"Context\"]  # 문서의 검색 결과\n",
    "    answer: Annotated[str, \"Answer\"]  # 답변\n",
    "    messages: Annotated[list, add_messages]  # 메시지(누적되는 list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph 구축\n",
    "class DataExtractor:\n",
    "    def __init__(\n",
    "        self, \n",
    "        file_folder:str=\"./data/input_data\", \n",
    "        file_number:int=1, \n",
    "        # db_folder:str=\"./vectordb\"\n",
    "    ):\n",
    "        if file_number < 10:\n",
    "            file_name = f\"paper_00{file_number}\"\n",
    "        elif file_number < 100:\n",
    "            file_name = f\"paper_0{file_number}\"\n",
    "        else:\n",
    "            file_name = f\"paper_{file_number}\"\n",
    "\n",
    "        self.retriever = embedding_file(\n",
    "            file_folder=file_folder, \n",
    "            file_name=file_name, \n",
    "            # db_folder=db_folder\n",
    "        )\n",
    "        \n",
    "        self.model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.5)\n",
    "        self.relevance_checker = ChatOpenAI(model=\"gpt-4o\", temperature=0.5)\n",
    "        self.llm_answer_prompt = \"\"\"\n",
    "        Based on the following document, please provide an answer to the given question.\n",
    "        Document:\n",
    "        {context}\n",
    "\n",
    "        Question:\n",
    "        {question}\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "        self.relevance_check_template = \"\"\"\n",
    "        You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the answer: {answer} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user answer, grade it as relevant. \\n\n",
    "        \n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the retrieved document is relevant to the answer.\n",
    "        If the retrieved document does not contain the values or information being searched for, and 'None' is provided as the answer, check if the response accurately reflects the absence of the requested information. If the absence is accurate and justified, grade the document as relevant even if the values are 'None'.\n",
    "        \"\"\"\n",
    "        \n",
    "        # 그래프 생성\n",
    "        bulider = StateGraph(GraphState)\n",
    "\n",
    "        # 노드 정의\n",
    "        bulider.add_node(\"retrieve\", self.retrieve_document)\n",
    "        bulider.add_node(\"relevance_check\", self.relevance_check)\n",
    "        bulider.add_node(\"llm_answer\", self.llm_answer)\n",
    "\n",
    "       # 엣지 정의\n",
    "        bulider.add_edge(\"retrieve\", \"llm_answer\")  # _start_ -> 검색 시작\n",
    "        bulider.add_edge(\"llm_answer\", \"relevance_check\")  # 답변 생성 -> 관련성 체크\n",
    "\n",
    "        # 조건부 엣지를 추가합니다.\n",
    "        bulider.add_conditional_edges(\n",
    "            \"relevance_check\",  # 관련성 체크 노드에서 나온 결과를 is_relevant 함수에 전달합니다.\n",
    "            self.is_relevant,\n",
    "            {\n",
    "                \"yes\": END,  # 관련성이 있으면 _end_로 이동합니다.\n",
    "                \"no\": \"retrieve\",  # 관련성이 없으면 다시 검색합니다.\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # 그래프 진입점 설정\n",
    "        bulider.set_entry_point(\"retrieve\")\n",
    "        \n",
    "        # 체크포인터 설정\n",
    "        memory = MemorySaver()\n",
    "\n",
    "        # 컴파일\n",
    "        self.graph = bulider.compile(checkpointer=memory)        \n",
    "        self.graph.get_graph().draw_mermaid_png(output_file_path=\"graph.png\")\n",
    "\n",
    "    \n",
    "    def format_docs(self, docs: list[Document]) -> str:\n",
    "        \"\"\"문시 리스트에서 텍스트를 추출하여 하나의 문자로 합치는 기능을 합니다.\n",
    "\n",
    "        Args:\n",
    "            docs (list[Document]): 여러 개의 Documnet 객체로 이루어진 리스트\n",
    "\n",
    "        Returns:\n",
    "            str: 모든 문서의 텍스트가 하나로 합쳐진 문자열을 반환\n",
    "        \"\"\"\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    \n",
    "    def retrieve_document(self, state: GraphState) -> GraphState:\n",
    "        \"\"\"문서에서 검색하여 질문과 관련성 있는 문서를 찾습니다.\n",
    "\n",
    "        Args:\n",
    "            state (GraphState): 질문을 상태에서 가져옵니다.\n",
    "\n",
    "        Returns:\n",
    "            GraphState: 검색된 문서를 context 키에 저장한 상태 변수\n",
    "        \"\"\"        \n",
    "        # 질문을 상태에서 가져옵니다.\n",
    "        latest_question = state[\"question\"]\n",
    "\n",
    "        # 문서에서 검색하여 관련성 있는 문서를 찾습니다.\n",
    "        retrieved_docs = self.retriever.invoke(latest_question)\n",
    "\n",
    "        # 검색된 문서를 형식화합니다.(프롬프트 입력으로 넣어주기 위함)\n",
    "        retrieved_docs = self.format_docs(retrieved_docs)\n",
    "\n",
    "        # 검색된 문서를 context 키에 저장합니다.\n",
    "        return GraphState(context=retrieved_docs)\n",
    "    \n",
    "    \n",
    "    def llm_answer(self, state: GraphState) -> GraphState:\n",
    "        \"\"\"프롬프트에 따라 LLM이 질문에 대한 답변을 출력합니다. \n",
    "\n",
    "        Args:\n",
    "            state (GraphState): 질문, 검색된 문서를 상태에서 가져옵니다. \n",
    "\n",
    "        Returns:\n",
    "            GraphState: json 형태로 생성된 답변, (유저의 질문, 답변) 메세지를 저장한 상태 변수\n",
    "        \"\"\"        \n",
    "        # 질문을 상태에서 가져옵니다.\n",
    "        latest_question = state[\"question\"]\n",
    "\n",
    "        # 검색된 문서를 상태에서 가져옵니다.\n",
    "        context = state[\"context\"]\n",
    "\n",
    "        # prompt 설정\n",
    "        prompt = PromptTemplate(\n",
    "            template=self.llm_answer_prompt,\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "            )\n",
    "\n",
    "        # 체인 호출\n",
    "        chain = prompt | self.model | JsonOutputParser()\n",
    "\n",
    "        response = chain.invoke(\n",
    "            {\n",
    "                \"question\": latest_question,\n",
    "                \"context\": context,\n",
    "                \"chat_history\": messages_to_history(state[\"messages\"]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 생성된 답변, (유저의 질문, 답변) 메시지를 상태에 저장합니다.\n",
    "        return GraphState(\n",
    "            answer=response,\n",
    "            messages=[(\"user\", latest_question), (\"assistant\", response)]\n",
    "        )\n",
    "\n",
    "\n",
    "    def relevance_check(self, state: GraphState) -> GraphState:\n",
    "        \"\"\"답변과 검색 문서 간의 관련성을 평가합니다. \n",
    "\n",
    "        Args:\n",
    "            state (GraphState): 검색된 문서와 답변을 가져옵니다. \n",
    "\n",
    "        Returns:\n",
    "            GraphState: 관련성 점수를 저장한 상태 변수\n",
    "        \"\"\"    \n",
    "        \n",
    "        class GradeAnswer(BaseModel):\n",
    "            \"\"\"Binary scoring to evaluate the appropriateness of answers to retrieval\"\"\"\n",
    "\n",
    "            binary_score: str = Field(\n",
    "                description=\"Indicate 'yes' or 'no' whether the answer solves the question\"\n",
    "            )\n",
    "            \n",
    "        # 프롬프트 생성\n",
    "        prompt = PromptTemplate(\n",
    "            template=self.relevance_check_template,\n",
    "            input_variables=[\"context\", \"answer\"],\n",
    "        )\n",
    "\n",
    "        # 체인\n",
    "        structured_relevance_checker = self.relevance_checker.with_structured_output(GradeAnswer)\n",
    "        relevance_chain = prompt | structured_relevance_checker\n",
    "        \n",
    "        # retrieval_answer_relevant = GroundednessChecker(\n",
    "        #     llm=self.relevance_checker, target=\"retrieval-answer\"\n",
    "        # ).create()\n",
    "\n",
    "        # 관련성 체크를 실행(\"yes\" or \"no\")\n",
    "        response = relevance_chain.invoke(\n",
    "            {\"context\": state[\"context\"], \"answer\": state[\"answer\"]}\n",
    "        )\n",
    "\n",
    "        print(f\"        RELEVANCE CHECK : {response.binary_score}\")\n",
    "\n",
    "        # 참고: 여기서의 관련성 평가기는 각자의 Prompt 를 사용하여 수정할 수 있습니다. 여러분들의 Groundedness Check 를 만들어 사용해 보세요!\n",
    "        return GraphState(relevance=response.binary_score)\n",
    "\n",
    "\n",
    "    def is_relevant(self, state: GraphState) -> GraphState:\n",
    "        \"\"\"관련성을 체크하는 함수\n",
    "\n",
    "        Args:\n",
    "            state (GraphState):\n",
    "\n",
    "        Returns:\n",
    "            GraphState: 관련성을 저장한 상태 변수\n",
    "        \"\"\"        \n",
    "        return state[\"relevance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_df_generator(\n",
    "    file_folder=\"./data/input_data/\",      ## input 논문이 있는 폴더 위치\n",
    "    file_num_list=[11, 16, 22],            ## 아직 8번 논문 안됨\n",
    "    question_number=1,                     ## question 번호 1,2,3,4 중 하나\n",
    "):\n",
    "    eval_df = pd.DataFrame(columns=[\"paper_number\", \"question\", \"ground_truth\", \"answer\", \"context\"])\n",
    "    for i, file_number in enumerate(file_num_list):\n",
    "        print(f\"#####   {file_number}번째 논문    #####\")\n",
    "        voltai_graph = DataExtractor(\n",
    "            file_folder=file_folder,\n",
    "            file_number=file_number\n",
    "        ).graph\n",
    "\n",
    "        # config 설정(재귀 최대 횟수, thread_id)\n",
    "        config = RunnableConfig(\n",
    "            recursion_limit=20, \n",
    "            # configurable={\"thread_id\": str(uuid.uuid4())}\n",
    "            configurable={\"thread_id\": random_uuid()}\n",
    "        )\n",
    "\n",
    "        # 4개의 질문에 대해 그래프 실행 및 출력\n",
    "        print(f\"    {question_number}번째 질문\")\n",
    "        result = voltai_graph.invoke(input={\"question\":question_list[question_number-1]}, config=config)\n",
    "\n",
    "        ### result 저장\n",
    "        ## gt 불러오기기\n",
    "        if file_number < 10:\n",
    "            file_name = f\"paper_00{file_number}\"\n",
    "        elif file_number < 100:\n",
    "            file_name = f\"paper_0{file_number}\"\n",
    "        else:\n",
    "            file_name = f\"paper_{file_number}\"\n",
    "    \n",
    "        # JSON 파일 경로\n",
    "        file_path = f\"./data/ground_truth/{file_name}_gt.json\"\n",
    "\n",
    "        # JSON 파일 읽기\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            gt = json.load(file)\n",
    "\n",
    "        ## df에 결과 저장하기       \n",
    "        if question_number == 1:\n",
    "            category_name = \"CAM (Cathode Active Material)\"\n",
    "        elif question_number == 2:\n",
    "            category_name = \"Electrode (only for coin-cell (half-cell))\"\n",
    "        elif question_number == 3:\n",
    "            category_name = \"Morphological results\"\n",
    "        elif question_number == 4:\n",
    "            category_name = \"Cathode Performance\"    \n",
    "        else:\n",
    "            raise\n",
    "        \n",
    "        eval_df.loc[i, \"paper_number\"] = file_number\n",
    "        eval_df.loc[i, \"question\"] = result[\"question\"].replace(\"\\n\", \"\")\n",
    "        eval_df.loc[i, \"answer\"] = [result[\"answer\"][0][category_name]]\n",
    "        eval_df.loc[i, \"ground_truth\"] = [gt[category_name]]\n",
    "        eval_df.loc[i, \"context\"] = result[\"context\"]\n",
    "        \n",
    "    return eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_num_list = [11, 16, 22]\n",
    "# question_number = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####   11번째 논문    #####\n",
      "    1번째 질문\n",
      "        RELEVANCE CHECK : yes\n",
      "#####   16번째 논문    #####\n",
      "    1번째 질문\n",
      "        RELEVANCE CHECK : yes\n",
      "#####   22번째 논문    #####\n",
      "    1번째 질문\n",
      "        RELEVANCE CHECK : yes\n"
     ]
    }
   ],
   "source": [
    "q1_eval_frame = eval_df_generator(\n",
    "    file_folder=\"./data/input_data/\",       ## input 논문이 있는 폴더 위치\n",
    "    file_num_list=file_num_list,            ## 아직 8번 논문 안됨\n",
    "    question_number=1,        ## question 번호 1,2,3,4 중 하나\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####   11번째 논문    #####\n",
      "    2번째 질문\n",
      "        RELEVANCE CHECK : yes\n",
      "#####   16번째 논문    #####\n",
      "    2번째 질문\n",
      "        RELEVANCE CHECK : no\n",
      "        RELEVANCE CHECK : yes\n",
      "#####   22번째 논문    #####\n",
      "    2번째 질문\n",
      "        RELEVANCE CHECK : yes\n"
     ]
    }
   ],
   "source": [
    "q2_eval_frame = eval_df_generator(\n",
    "    file_folder=\"./data/input_data/\",       ## input 논문이 있는 폴더 위치\n",
    "    file_num_list=file_num_list,            ## 아직 8번 논문 안됨\n",
    "    question_number=2,        ## question 번호 1,2,3,4 중 하나\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q3_eval_frame = eval_df_generator(\n",
    "#     file_folder=\"./data/input_data/\",       ## input 논문이 있는 폴더 위치\n",
    "#     file_num_list=file_num_list,            ## 아직 8번 논문 안됨\n",
    "#     question_number=3,        ## question 번호 1,2,3,4 중 하나\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q4_eval_frame = eval_df_generator(\n",
    "#     file_folder=\"./data/input_data/\",       ## input 논문이 있는 폴더 위치\n",
    "#     file_num_list=file_num_list,            ## 아직 8번 논문 안됨\n",
    "#     question_number=4,        ## question 번호 1,2,3,4 중 하나\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_number</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Below are instructions for filling out items b...</td>\n",
       "      <td>[{'Stoichiometry information': {'LiNi1/3Co1/3M...</td>\n",
       "      <td>[{'Stoichiometry information': {'NCM-111': {'L...</td>\n",
       "      <td>kinetics of the intercalation/deintercalation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>Below are instructions for filling out items b...</td>\n",
       "      <td>[{'Stoichiometry information': {'LiNi1/3Co1/3M...</td>\n",
       "      <td>[{'Stoichiometry information': {'NCM': {'Li ra...</td>\n",
       "      <td>was conducted on the electrochemical equipment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Below are instructions for filling out items b...</td>\n",
       "      <td>[{'Stoichiometry information': {'LiNi0.84Co0.1...</td>\n",
       "      <td>[{'Stoichiometry information': {'NCM-622': {'L...</td>\n",
       "      <td>2Scientific  RepoRts  |          (2019) 9:8952...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  paper_number                                           question  \\\n",
       "0           11  Below are instructions for filling out items b...   \n",
       "1           16  Below are instructions for filling out items b...   \n",
       "2           22  Below are instructions for filling out items b...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  [{'Stoichiometry information': {'LiNi1/3Co1/3M...   \n",
       "1  [{'Stoichiometry information': {'LiNi1/3Co1/3M...   \n",
       "2  [{'Stoichiometry information': {'LiNi0.84Co0.1...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  [{'Stoichiometry information': {'NCM-111': {'L...   \n",
       "1  [{'Stoichiometry information': {'NCM': {'Li ra...   \n",
       "2  [{'Stoichiometry information': {'NCM-622': {'L...   \n",
       "\n",
       "                                             context  \n",
       "0  kinetics of the intercalation/deintercalation ...  \n",
       "1  was conducted on the electrochemical equipment...  \n",
       "2  2Scientific  RepoRts  |          (2019) 9:8952...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_eval_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_number</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Below are instructions for filling out items b...</td>\n",
       "      <td>[{'Active material to Conductive additive to B...</td>\n",
       "      <td>[{'Active material to Conductive additive to B...</td>\n",
       "      <td>or to utilize conductive additives such as gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>Below are instructions for filling out items b...</td>\n",
       "      <td>[{'Active material to Conductive additive to B...</td>\n",
       "      <td>[{'Active material to Conductive additive to B...</td>\n",
       "      <td>Notes\\nThe authors declare no competingﬁnancia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Below are instructions for filling out items b...</td>\n",
       "      <td>[{'Active material to Conductive additive to B...</td>\n",
       "      <td>[{'Active material to Conductive additive to B...</td>\n",
       "      <td>2Scientific  RepoRts  |          (2019) 9:8952...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  paper_number                                           question  \\\n",
       "0           11  Below are instructions for filling out items b...   \n",
       "1           16  Below are instructions for filling out items b...   \n",
       "2           22  Below are instructions for filling out items b...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  [{'Active material to Conductive additive to B...   \n",
       "1  [{'Active material to Conductive additive to B...   \n",
       "2  [{'Active material to Conductive additive to B...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  [{'Active material to Conductive additive to B...   \n",
       "1  [{'Active material to Conductive additive to B...   \n",
       "2  [{'Active material to Conductive additive to B...   \n",
       "\n",
       "                                             context  \n",
       "0  or to utilize conductive additives such as gra...  \n",
       "1  Notes\\nThe authors declare no competingﬁnancia...  \n",
       "2  2Scientific  RepoRts  |          (2019) 9:8952...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_eval_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q3_eval_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q4_eval_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 임의로 설정한 sentence template에 value들을 넣어서 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sentence_generator(question_number, values):\n",
    "    if question_number == 1:\n",
    "        return f\"The {values[0]} is {values[1]} commercially obtained, and synthesized with {values[2]}, and {values[3]}, and, {values[4]} for {values[5]} at {values[6]}, with {values[7]} doping and {values[8]} coating and {values[9]} treatment.\"\n",
    "    elif question_number == 2:\n",
    "        return f\"The electrode is manufactured by {values[0]} with {values[1]} and {values[2]} is {values[3]} for {values[4]}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_eval_frame[\"ground_truth_sentence\"] = q1_eval_frame[\"ground_truth\"].apply(lambda x: eval_sentence_generator(1, list(x[0].values())))\n",
    "q1_eval_frame[\"answer_sentence\"] = q1_eval_frame[\"answer\"].apply(lambda x: eval_sentence_generator(1, list(x[0].values()))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_eval_frame[\"ground_truth_sentence\"] = q2_eval_frame[\"ground_truth\"].apply(lambda x: eval_sentence_generator(question_number=2, values=list(x[0].values())))\n",
    "q2_eval_frame[\"answer_sentence\"] = q2_eval_frame[\"answer\"].apply(lambda x: eval_sentence_generator(question_number=2, values=list(x[0].values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모든 metric data frame\n",
    "q1_all_metric_df = q1_eval_frame[[\"ground_truth_sentence\", \"answer_sentence\"]].apply(\n",
    "    lambda row: evaluate_all_metrics(row[\"ground_truth_sentence\"], row[\"answer_sentence\"]), \n",
    "    axis=1\n",
    ").apply(pd.Series)\n",
    "\n",
    "## rouge 수정\n",
    "q1_rouge_df = q1_all_metric_df[\"ROUGE\"].apply(pd.Series)\n",
    "\n",
    "## 최종 evaluation data frame\n",
    "q1_eval_df = pd.concat([q1_eval_frame, q1_all_metric_df.drop(columns=[\"ROUGE\"]), q1_rouge_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_number</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>ground_truth_sentence</th>\n",
       "      <th>answer_sentence</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>Semantic Similarity (STS)</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Below are instructions for filling out items b...</td>\n",
       "      <td>[{'Stoichiometry information': {'LiNi1/3Co1/3M...</td>\n",
       "      <td>[{'Stoichiometry information': {'NCM-111': {'L...</td>\n",
       "      <td>kinetics of the intercalation/deintercalation ...</td>\n",
       "      <td>The {'LiNi1/3Co1/3Mn1/3O2': {'Li ratio': '1', ...</td>\n",
       "      <td>The {'NCM-111': {'Li ratio': '1', 'Ni ratio': ...</td>\n",
       "      <td>0.614218</td>\n",
       "      <td>0.687410</td>\n",
       "      <td>0.843172</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>Below are instructions for filling out items b...</td>\n",
       "      <td>[{'Stoichiometry information': {'LiNi1/3Co1/3M...</td>\n",
       "      <td>[{'Stoichiometry information': {'NCM': {'Li ra...</td>\n",
       "      <td>was conducted on the electrochemical equipment...</td>\n",
       "      <td>The {'LiNi1/3Co1/3Mn1/3O2': {'Li ratio': '1', ...</td>\n",
       "      <td>The {'NCM': {'Li ratio': '1.0', 'Ni ratio': '0...</td>\n",
       "      <td>0.469670</td>\n",
       "      <td>0.726418</td>\n",
       "      <td>0.852117</td>\n",
       "      <td>0.671329</td>\n",
       "      <td>0.524823</td>\n",
       "      <td>0.657343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Below are instructions for filling out items b...</td>\n",
       "      <td>[{'Stoichiometry information': {'LiNi0.84Co0.1...</td>\n",
       "      <td>[{'Stoichiometry information': {'NCM-622': {'L...</td>\n",
       "      <td>2Scientific  RepoRts  |          (2019) 9:8952...</td>\n",
       "      <td>The {'LiNi0.84Co0.10Mn0.06O2': {'Li ratio': '1...</td>\n",
       "      <td>The {'NCM-622': {'Li ratio': 'None', 'Ni ratio...</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>0.698779</td>\n",
       "      <td>0.691044</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.584270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  paper_number                                           question  \\\n",
       "0           11  Below are instructions for filling out items b...   \n",
       "1           16  Below are instructions for filling out items b...   \n",
       "2           22  Below are instructions for filling out items b...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  [{'Stoichiometry information': {'LiNi1/3Co1/3M...   \n",
       "1  [{'Stoichiometry information': {'LiNi1/3Co1/3M...   \n",
       "2  [{'Stoichiometry information': {'LiNi0.84Co0.1...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  [{'Stoichiometry information': {'NCM-111': {'L...   \n",
       "1  [{'Stoichiometry information': {'NCM': {'Li ra...   \n",
       "2  [{'Stoichiometry information': {'NCM-622': {'L...   \n",
       "\n",
       "                                             context  \\\n",
       "0  kinetics of the intercalation/deintercalation ...   \n",
       "1  was conducted on the electrochemical equipment...   \n",
       "2  2Scientific  RepoRts  |          (2019) 9:8952...   \n",
       "\n",
       "                               ground_truth_sentence  \\\n",
       "0  The {'LiNi1/3Co1/3Mn1/3O2': {'Li ratio': '1', ...   \n",
       "1  The {'LiNi1/3Co1/3Mn1/3O2': {'Li ratio': '1', ...   \n",
       "2  The {'LiNi0.84Co0.10Mn0.06O2': {'Li ratio': '1...   \n",
       "\n",
       "                                     answer_sentence      BLEU    METEOR  \\\n",
       "0  The {'NCM-111': {'Li ratio': '1', 'Ni ratio': ...  0.614218  0.687410   \n",
       "1  The {'NCM': {'Li ratio': '1.0', 'Ni ratio': '0...  0.469670  0.726418   \n",
       "2  The {'NCM-622': {'Li ratio': 'None', 'Ni ratio...  0.401726  0.698779   \n",
       "\n",
       "   Semantic Similarity (STS)    rouge1    rouge2    rougeL  \n",
       "0                   0.843172  0.703125  0.539683  0.640625  \n",
       "1                   0.852117  0.671329  0.524823  0.657343  \n",
       "2                   0.691044  0.629213  0.488636  0.584270  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모든 metric data frame\n",
    "q2_all_metric_df = q2_eval_frame[[\"ground_truth_sentence\", \"answer_sentence\"]].apply(\n",
    "    lambda row: evaluate_all_metrics(row[\"ground_truth_sentence\"], row[\"answer_sentence\"]), \n",
    "    axis=1\n",
    ").apply(pd.Series)\n",
    "\n",
    "## rouge 수정\n",
    "q2_rouge_df = q2_all_metric_df[\"ROUGE\"].apply(pd.Series)\n",
    "\n",
    "## 최종 evaluation data frame\n",
    "q2_eval_df = pd.concat([q2_eval_frame, q2_all_metric_df.drop(columns=[\"ROUGE\"]), q2_rouge_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_number</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>ground_truth_sentence</th>\n",
       "      <th>answer_sentence</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>Semantic Similarity (STS)</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Below are instructions for filling out items b...</td>\n",
       "      <td>[{'Active material to Conductive additive to B...</td>\n",
       "      <td>[{'Active material to Conductive additive to B...</td>\n",
       "      <td>or to utilize conductive additives such as gra...</td>\n",
       "      <td>The electrode is manufactured by NCM : RGO : P...</td>\n",
       "      <td>The electrode is manufactured by None with {'S...</td>\n",
       "      <td>0.424187</td>\n",
       "      <td>0.589008</td>\n",
       "      <td>0.882969</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>0.683544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>Below are instructions for filling out items b...</td>\n",
       "      <td>[{'Active material to Conductive additive to B...</td>\n",
       "      <td>[{'Active material to Conductive additive to B...</td>\n",
       "      <td>Notes\\nThe authors declare no competingﬁnancia...</td>\n",
       "      <td>The electrode is manufactured by 80:15:5 with ...</td>\n",
       "      <td>The electrode is manufactured by 80 : 5 : 15 w...</td>\n",
       "      <td>0.511568</td>\n",
       "      <td>0.684932</td>\n",
       "      <td>0.949423</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.816901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Below are instructions for filling out items b...</td>\n",
       "      <td>[{'Active material to Conductive additive to B...</td>\n",
       "      <td>[{'Active material to Conductive additive to B...</td>\n",
       "      <td>2Scientific  RepoRts  |          (2019) 9:8952...</td>\n",
       "      <td>The electrode is manufactured by 96: 2: 2 with...</td>\n",
       "      <td>The electrode is manufactured by 96 : 2 : 2 wi...</td>\n",
       "      <td>0.460498</td>\n",
       "      <td>0.613626</td>\n",
       "      <td>0.952416</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.781609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  paper_number                                           question  \\\n",
       "0           11  Below are instructions for filling out items b...   \n",
       "1           16  Below are instructions for filling out items b...   \n",
       "2           22  Below are instructions for filling out items b...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  [{'Active material to Conductive additive to B...   \n",
       "1  [{'Active material to Conductive additive to B...   \n",
       "2  [{'Active material to Conductive additive to B...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  [{'Active material to Conductive additive to B...   \n",
       "1  [{'Active material to Conductive additive to B...   \n",
       "2  [{'Active material to Conductive additive to B...   \n",
       "\n",
       "                                             context  \\\n",
       "0  or to utilize conductive additives such as gra...   \n",
       "1  Notes\\nThe authors declare no competingﬁnancia...   \n",
       "2  2Scientific  RepoRts  |          (2019) 9:8952...   \n",
       "\n",
       "                               ground_truth_sentence  \\\n",
       "0  The electrode is manufactured by NCM : RGO : P...   \n",
       "1  The electrode is manufactured by 80:15:5 with ...   \n",
       "2  The electrode is manufactured by 96: 2: 2 with...   \n",
       "\n",
       "                                     answer_sentence      BLEU    METEOR  \\\n",
       "0  The electrode is manufactured by None with {'S...  0.424187  0.589008   \n",
       "1  The electrode is manufactured by 80 : 5 : 15 w...  0.511568  0.684932   \n",
       "2  The electrode is manufactured by 96 : 2 : 2 wi...  0.460498  0.613626   \n",
       "\n",
       "   Semantic Similarity (STS)    rouge1    rouge2    rougeL  \n",
       "0                   0.882969  0.683544  0.597403  0.683544  \n",
       "1                   0.949423  0.845070  0.637681  0.816901  \n",
       "2                   0.952416  0.781609  0.658824  0.781609  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "# print(\"#############################################################\")\n",
    "# pprint(\"question1 ground truth sentence\")\n",
    "# pprint(q1_eval_df[\"ground_truth_sentence\"][0])\n",
    "# print(\"#############################################################\")\n",
    "# pprint(\"question1 answer sentence\")\n",
    "# pprint(q1_eval_df[\"answer_sentence\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"#############################################################\")\n",
    "# pprint(\"question2 ground truth sentence\")\n",
    "# pprint(q2_eval_df[\"ground_truth_sentence\"][0])\n",
    "# print(\"#############################################################\")\n",
    "# pprint(\"question2 answer sentence\")\n",
    "# pprint(q2_eval_df[\"answer_sentence\"][0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voltai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
