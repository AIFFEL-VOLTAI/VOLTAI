{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "from langchain_teddynote import logging\n",
    "from models import Agent, get_rag_instance\n",
    "\n",
    "from utils import save_output2json\n",
    "from prompt import load_system_prompt, load_invoke_input\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage, HumanMessage\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation\n",
    "from typing import Annotated, Sequence, TypedDict, List\n",
    "from typing_extensions import TypedDict\n",
    "import functools\n",
    "\n",
    "from retriever.retriever_handler import get_retriever\n",
    "from utils.model_handler import get_llm\n",
    "from utils.utils import format_docs\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.tools import Tool\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env 파일 로드\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "# API 키 가져오기\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# LangSmith 추적 기능을 활성화합니다. (선택적)\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SampleNameSearcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = get_retriever(\n",
    "            file_folder=\"./data/raw\", \n",
    "            file_number=11,\n",
    "            chunk_size=500, \n",
    "            chunk_overlap=100, \n",
    "            search_k=10\n",
    "        )\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.1)\n",
    "\n",
    "sample_name_retriever_prompt = \"\"\"\n",
    "You are an expert assistant specializing in extracting information from research papers related to battery technology. Your role is to carefully analyze the provided document.\n",
    "\n",
    "Document:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", sample_name_retriever_prompt), \n",
    "    (\"human\", \"{sample_name_question}\")\n",
    "])\n",
    "\n",
    "sample_name_searcher_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs, \n",
    "        \"sample_name_question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt \n",
    "    | model \n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name_question = \"\"\"\n",
    "Use all of the NCM cathode sample names (e.g., 'NCM-622', 'pristine NCM', 'M-NCM') provided in the electrochemical performance section. You just output sample names. Do Not output like '- NCM622' , just output 'NCM622.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = sample_name_searcher_chain.invoke(sample_name_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NR0', 'NR1', 'NR3', 'NR5']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 에이전트와 도구에 대한 다른 노드를 생성할 것입니다. 이 클래스는 그래프의 각 노드 사이에서 전달되는 객체를 정의합니다.\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    sender: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "def create_supervisor(model_name, members: list, system_prompt: str=None):            \n",
    "    options_for_next = [\"FINISH\"] + members\n",
    "\n",
    "    # 작업자 선택 응답 모델 정의: 다음 작업자를 선택하거나 작업 완료를 나타냄\n",
    "    class RouteResponse(BaseModel):\n",
    "        next: Literal[*options_for_next]\n",
    "\n",
    "    # ChatPromptTemplate 생성\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            (\n",
    "                \"system\",\n",
    "                \"Given the conversation above, who should act next? \"\n",
    "                \"Or should we FINISH? Select one of: {options}\",\n",
    "            ),\n",
    "        ]\n",
    "    ).partial(options=str(options_for_next), members=\", \".join(members))\n",
    "\n",
    "    llm = get_llm(model_name, temperature=0.1)\n",
    "    \n",
    "    return prompt | llm.with_structured_output(RouteResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Supervisor 시스템 프롬프트\n",
    "supervisor_system_prompt = \"\"\"\n",
    "You are the Supervisor, responsible for managing the structured extraction and verification process of lithium-ion battery-related scientific papers. Your primary task is to coordinate the Researcher and Verifier agents to ensure that the final extracted information is accurate, structured, and technically precise before submission.\n",
    "\n",
    "## Workflow:\n",
    "1. Question Breakdown:\n",
    "\n",
    "    - You receive a user query that requires extracting information from a scientific paper.\n",
    "    - You break down the query into multiple sub-questions, categorizing them into four specific groups for systematic extraction.\n",
    "    - You then assign each set of sub-questions to different Researcher Agents.\n",
    "\n",
    "2. Researcher Phase:\n",
    "\n",
    "    - Each Researcher extracts information from the paper in response to their assigned sub-questions.\n",
    "    - The extracted information must be written as a single, coherent technical paragraph, not in bullet points or lists.\n",
    "    - The response must use precise scientific language, ensuring accuracy and logical flow.\n",
    "\n",
    "3. Verification Phase:\n",
    "\n",
    "    - Once a Researcher submits their response, it is passed to a Verifier Agent for validation.\n",
    "    - The Verifier must check the Researcher’s response using a retriever tool to ensure that the information exactly matches what is stated in the paper.\n",
    "    - If any incorrect, missing, or assumed information is detected, the Verifier provides detailed feedback and requests a correction from the Researcher.\n",
    "    - The Researcher must revise the response based on the feedback and resubmit it for final verification.\n",
    "\n",
    "4. Final Answer Compilation:\n",
    "\n",
    "    - If the Verifier confirms that the extracted information is correct, they submit the validated response to the Supervisor with the marker: `### Complete Verification`.\n",
    "    - The Supervisor collects all verified responses from multiple Verifiers and compiles them into a single structured answer, ensuring coherence and completeness.\n",
    "    - The final output is then delivered to the user.\n",
    "\n",
    "## Guidelines:\n",
    "    - Every response must be a well-structured technical paragraph using precise scientific terminology (e.g., \"was synthesized by,\" \"was reported,\" \"was not mentioned\").\n",
    "    - No assumptions or hallucinations are allowed; if a detail is not reported in the paper, it must be explicitly stated.\n",
    "    - The Verifier must always cross-check the Researcher's response against the source paper before approving.\n",
    "    - The Supervisor only compiles and submits fully verified information—no modifications should be made after verification.\n",
    "\n",
    "As the Supervisor, your role is to ensure the smooth execution of this multi-step process and deliver an accurate, structured, and expert-level summary of the scientific paper.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = [f\"Researcher{i}\" for i in range(1, 5)] + [f\"Verifier{i}\" for i in range(1, 5)]\n",
    "\n",
    "# Supervisor Agent 생성\n",
    "def supervisor_agent(state):\n",
    "    # 프롬프트와 LLM을 결합하여 체인 구성\n",
    "    supervisor_chain = create_supervisor(\"gpt-4o\", members, supervisor_system_prompt)\n",
    "    # Agent 호출\n",
    "    return supervisor_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Researcher & Verifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(model_name, tools, system_message: str):\n",
    "    # 에이전트를 생성합니다.\n",
    "    functions = [format_tool_to_openai_function(t) for t in tools]\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "                \" Use the provided tools to progress towards answering the question.\"                                        \n",
    "                \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "                \" will help where you left off. Execute what you can to make progress.\"\n",
    "                \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "                \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    prompt = prompt.partial(tool_names=\", \".join(\n",
    "        [tool.name for tool in tools]))\n",
    "    llm = get_llm(model_name, temperature=0.1)\n",
    "    \n",
    "    return prompt | llm.bind_functions(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Researcher 시스템 프롬프트\n",
    "researcher_system_prompt = \"\"\"\n",
    "You are a Researcher Agent, responsible for extracting structured and detailed information from scientific papers, specifically in the field of lithium-ion battery materials. Your task is to answer a specific sub-question assigned by the Supervisor by retrieving information from the given paper.\n",
    "\n",
    "## Your Responsibilities:\n",
    "    1. Extract information strictly from the paper without making assumptions or hallucinations.\n",
    "    2. Write the response as a single, coherent technical paragraph (not bullet points or lists).\n",
    "    3. Use precise scientific language, such as:\n",
    "        - \"was synthesized by...\"\n",
    "        - \"was reported to exhibit...\"\n",
    "        - \"was not mentioned in the paper...\"\n",
    "    4. If a detail is not reported in the paper, explicitly state it (e.g., “The composition data was not mentioned.”).\n",
    "    5. Maintain logical flow and consistency in your paragraph.\n",
    "    6. Once you complete your response, submit it to the Verifier for validation.\n",
    "\n",
    "After submitting, you may receive feedback from the Verifier. If your response contains incorrect, missing, or unclear information, you must revise and resubmit it based on the Verifier’s comments.\n",
    "\"\"\"\n",
    "\n",
    "## Verifier 시스템 프롬프트\n",
    "verifier_system_prompt = \"\"\"\n",
    "You are a Verifier Agent, responsible for validating the responses provided by the Researcher. Your primary task is to check for accuracy, completeness, and adherence to scientific precision by cross-referencing the information with the given scientific paper.\n",
    "\n",
    "## Your Responsibilities:\n",
    "    1. Verify the Researcher’s response using the retriever tool to ensure it is fully supported by the paper.\n",
    "    2. Identify any incorrect, missing, or assumed information and provide precise feedback to the Researcher.\n",
    "    3. If a required detail is not present in the paper, ensure that the Researcher has correctly stated that it was \"not reported.\"\n",
    "    4. Maintain strict scientific language and formatting consistency.\n",
    "    5. Once a response is fully verified and correct, submit it to the Supervisor with the marker: `### Complete Verification`\n",
    "\n",
    "If you find errors, return the response to the Researcher with clear feedback so they can revise and resubmit.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## retriever 설정\n",
    "retriever = get_retriever(\n",
    "    file_folder=\"./data/raw\", \n",
    "    file_number=11,\n",
    "    chunk_size=500, \n",
    "    chunk_overlap=100, \n",
    "    search_k=10\n",
    ")\n",
    "retriever_tool = Tool(\n",
    "    name=\"retriever\",\n",
    "    func=retriever.get_relevant_documents,\n",
    "    description=\"Retrieve relevant documents based on a query.\"\n",
    ")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_agent = create_agent(\"gpt-4o\", [retriever_tool], researcher_system_prompt)\n",
    "verifier_agent = create_agent(\"gpt-4o\", [retriever_tool], verifier_system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample_name_searcher_node(state):\n",
    "#     \"\"\"\n",
    "#     SampleNameSearcher가 질문을 받고 샘플 이름을 찾아 state에 저장하는 함수.\n",
    "#     \"\"\"\n",
    "#     sample_name_question = state.get(\"sample_name_question\", \"\")  # 사용자의 질문을 가져옴\n",
    "#     sample_name = sample_name_searcher_chain.invoke(sample_name_question)  # 질문과 관련된 샘플 이름 검색\n",
    "#     state[\"sample_name\"] = sample_name  # 결과 저장\n",
    "    \n",
    "#     return state  # Supervisor에게 전달할 state 반환\n",
    "\n",
    "# def supervisor_node(state):\n",
    "#     \"\"\"\n",
    "#     Supervisor가 SampleNameSearcher의 결과를 받아서 다음 단계를 수행하는 함수.\n",
    "#     \"\"\"\n",
    "#     sample_names = state.get(\"sample_name\", \"\")  # SampleNameSearcher에서 찾은 샘플 이름\n",
    "#     supervisor_question = state.get(\"supervisor_question\", \"\")  # 원래 질문\n",
    "\n",
    "#     # Supervisor가 사용할 입력 데이터 생성\n",
    "#     combined_input = f\"Sample Name: {sample_names}\\nQuestion: {supervisor_question}\"\n",
    "    \n",
    "#     result = supervisor_agent.invoke(combined_input)  # Supervisor 실행\n",
    "    \n",
    "#     state[\"sub_question\"] = result  # 결과 저장\n",
    "#     return state  # 다음 노드로 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state, agent, name):\n",
    "    agent_response = agent.invoke(state)\n",
    "\n",
    "    if isinstance(agent_response, FunctionMessage):\n",
    "        pass\n",
    "    else:\n",
    "        agent_response = HumanMessage(**agent_response.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    return {\n",
    "        \"messages\":  [\n",
    "            HumanMessage(content=agent_response[\"messages\"][-1].content, name=name)\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervisor_node = functools.partial(agent_node, agent=supervisor_agent, name=\"Supervisor\")\n",
    "# sample_name_searcher_node = functools.partial(agent_node, agent=sample_name_searcher_chain, name=\"SampleNameSearcher\")\n",
    "\n",
    "# researcher_node = functools.partial(agent_node, agent=researcher_agent, name=\"Researcher\")\n",
    "# verifier_node = functools.partial(agent_node, agent=verifier_agent, name=\"Verifier\")\n",
    "\n",
    "researcher1_node = functools.partial(agent_node, agent=researcher_agent, name=\"Researcher1\")\n",
    "verifier1_node = functools.partial(agent_node, agent=verifier_agent, name=\"Verifier1\")\n",
    "\n",
    "researcher2_node = functools.partial(agent_node, agent=researcher_agent, name=\"Researcher2\")\n",
    "verifier2_node = functools.partial(agent_node, agent=verifier_agent, name=\"Verifier2\")\n",
    "\n",
    "researcher3_node = functools.partial(agent_node, agent=researcher_agent, name=\"Researcher3\")\n",
    "verifier3_node = functools.partial(agent_node, agent=verifier_agent, name=\"Verifier3\")\n",
    "\n",
    "researcher4_node = functools.partial(agent_node, agent=researcher_agent, name=\"Researcher4\")\n",
    "verifier4_node = functools.partial(agent_node, agent=verifier_agent, name=\"Verifier4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set tool\n",
    "tools = [retriever_tool]\n",
    "tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_node(state):\n",
    "    # 그래프에서 도구를 실행하는 함수입니다.\n",
    "    # 에이전트 액션을 입력받아 해당 도구를 호출하고 결과를 반환합니다.\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # 계속 조건에 따라 마지막 메시지가 함수 호출을 포함하고 있음을 알 수 있습니다.\n",
    "    first_message = messages[0]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # ToolInvocation을 함수 호출로부터 구성합니다.\n",
    "    tool_input = json.loads(last_message.additional_kwargs[\"function_call\"][\"arguments\"])\n",
    "    tool_name = last_message.additional_kwargs[\"function_call\"][\"name\"]\n",
    "    \n",
    "    if tool_name == \"retriever\":\n",
    "        base_query = tool_input.get(\"__arg1\", \"\")  # 기존 query 가져오기\n",
    "        refined_query = f\"Context: {first_message.content} | Query: {base_query}\"\n",
    "        tool_input[\"__arg1\"] = refined_query\n",
    "    \n",
    "    # 단일 인자 입력은 값으로 직접 전달할 수 있습니다.\n",
    "    if len(tool_input) == 1 and \"__arg1\" in tool_input:\n",
    "        tool_input = next(iter(tool_input.values()))\n",
    "    \n",
    "    action = ToolInvocation(\n",
    "        tool=tool_name,\n",
    "        tool_input=tool_input,\n",
    "    )\n",
    "    \n",
    "    # 도구 실행자를 호출하고 응답을 받습니다.\n",
    "    response = tool_executor.invoke(action)\n",
    "    \n",
    "    # 응답을 사용하여 FunctionMessage를 생성합니다.\n",
    "    function_message = FunctionMessage(\n",
    "        content=f\"{tool_name} response: {str(response)}\", name=action.tool\n",
    "    )\n",
    "    \n",
    "    # 기존 리스트에 추가될 리스트를 반환합니다.\n",
    "    return {\"messages\": [function_message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state):\n",
    "    # 상태 정보를 기반으로 다음 단계를 결정하는 라우터 함수\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if \"function_call\" in last_message.additional_kwargs:\n",
    "        return \"call_tool\"\n",
    "    \n",
    "    if \"### Complete Verification\" in last_message.content:\n",
    "        return \"save_answer\"\n",
    "    \n",
    "    if \"### Final Answer\" in last_message.content:\n",
    "        return \"output\"\n",
    "    \n",
    "    return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## graph 구축\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Supervisor\", supervisor_agent)\n",
    "\n",
    "workflow.add_node(\"Researcher1\", researcher1_node)\n",
    "workflow.add_node(\"Researcher2\", researcher2_node)\n",
    "workflow.add_node(\"Researcher3\", researcher3_node)\n",
    "workflow.add_node(\"Researcher4\", researcher4_node)\n",
    "\n",
    "workflow.add_node(\"Verifier1\", verifier1_node)\n",
    "workflow.add_node(\"Verifier2\", verifier2_node)\n",
    "workflow.add_node(\"Verifier3\", verifier3_node)\n",
    "workflow.add_node(\"Verifier4\", verifier4_node)\n",
    "\n",
    "for i in range(1, 5):\n",
    "    workflow.add_node(f\"call_tool{i}\", tool_node)\n",
    "    workflow.add_edge(\"Supervisor\", f\"Researcher{i}\")\n",
    "    workflow.add_conditional_edges(\n",
    "        f\"Researcher{i}\",\n",
    "        router,\n",
    "        {\"continue\": f\"Verifier{i}\", \"call_tool\": f\"call_tool{i}\"},\n",
    "    )\n",
    "    workflow.add_conditional_edges(\n",
    "        f\"Verifier{i}\",\n",
    "        router,\n",
    "        {\"continue\": f\"Researcher{i}\", \"call_tool\": f\"call_tool{i}\", \"save_answer\": \"Supervisor\"}, \n",
    "    )\n",
    "    workflow.add_conditional_edges(\n",
    "        f\"call_tool{i}\",\n",
    "        lambda x: x[\"sender\"],\n",
    "        {\n",
    "            f\"Researcher{i}\": f\"Researcher{i}\",\n",
    "            f\"Verifier{i}\": f\"Verifier{i}\",\n",
    "        },\n",
    "    )\n",
    "    \n",
    "workflow.set_entry_point(\"Supervisor\")\n",
    "workflow.add_edge(\"Supervisor\", END)\n",
    "graph = workflow.compile()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%{init: {'flowchart': {'curve': 'linear'}}}%%\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tSupervisor(Supervisor)\n",
      "\tResearcher1(Researcher1)\n",
      "\tResearcher2(Researcher2)\n",
      "\tResearcher3(Researcher3)\n",
      "\tResearcher4(Researcher4)\n",
      "\tVerifier1(Verifier1)\n",
      "\tVerifier2(Verifier2)\n",
      "\tVerifier3(Verifier3)\n",
      "\tVerifier4(Verifier4)\n",
      "\tcall_tool1(call_tool1)\n",
      "\tcall_tool2(call_tool2)\n",
      "\tcall_tool3(call_tool3)\n",
      "\tcall_tool4(call_tool4)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\tSupervisor --> Researcher1;\n",
      "\tSupervisor --> Researcher2;\n",
      "\tSupervisor --> Researcher3;\n",
      "\tSupervisor --> Researcher4;\n",
      "\tSupervisor --> __end__;\n",
      "\t__start__ --> Supervisor;\n",
      "\tResearcher1 -. &nbsp;continue&nbsp; .-> Verifier1;\n",
      "\tResearcher1 -. &nbsp;call_tool&nbsp; .-> call_tool1;\n",
      "\tVerifier1 -. &nbsp;continue&nbsp; .-> Researcher1;\n",
      "\tVerifier1 -. &nbsp;call_tool&nbsp; .-> call_tool1;\n",
      "\tVerifier1 -. &nbsp;save_answer&nbsp; .-> Supervisor;\n",
      "\tcall_tool1 -.-> Researcher1;\n",
      "\tcall_tool1 -.-> Verifier1;\n",
      "\tResearcher2 -. &nbsp;continue&nbsp; .-> Verifier2;\n",
      "\tResearcher2 -. &nbsp;call_tool&nbsp; .-> call_tool2;\n",
      "\tVerifier2 -. &nbsp;continue&nbsp; .-> Researcher2;\n",
      "\tVerifier2 -. &nbsp;call_tool&nbsp; .-> call_tool2;\n",
      "\tVerifier2 -. &nbsp;save_answer&nbsp; .-> Supervisor;\n",
      "\tcall_tool2 -.-> Researcher2;\n",
      "\tcall_tool2 -.-> Verifier2;\n",
      "\tResearcher3 -. &nbsp;continue&nbsp; .-> Verifier3;\n",
      "\tResearcher3 -. &nbsp;call_tool&nbsp; .-> call_tool3;\n",
      "\tVerifier3 -. &nbsp;continue&nbsp; .-> Researcher3;\n",
      "\tVerifier3 -. &nbsp;call_tool&nbsp; .-> call_tool3;\n",
      "\tVerifier3 -. &nbsp;save_answer&nbsp; .-> Supervisor;\n",
      "\tcall_tool3 -.-> Researcher3;\n",
      "\tcall_tool3 -.-> Verifier3;\n",
      "\tResearcher4 -. &nbsp;continue&nbsp; .-> Verifier4;\n",
      "\tResearcher4 -. &nbsp;call_tool&nbsp; .-> call_tool4;\n",
      "\tVerifier4 -. &nbsp;continue&nbsp; .-> Researcher4;\n",
      "\tVerifier4 -. &nbsp;call_tool&nbsp; .-> call_tool4;\n",
      "\tVerifier4 -. &nbsp;save_answer&nbsp; .-> Supervisor;\n",
      "\tcall_tool4 -.-> Researcher4;\n",
      "\tcall_tool4 -.-> Verifier4;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(graph.get_graph().draw_mermaid())\n",
    "# graph.get_graph().draw_mermaid_png(output_file_path=\"MultiAgentSupervisor.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플 별로 다 찾아라는 프롬프트 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor_question = f\"\"\"\n",
    "## Sample Names: \n",
    "{sample_names}\n",
    "\n",
    "## Question : \n",
    "- The exact chemical composition (stoichiometry) of the cathode active material (CAM) used in the study\n",
    "- The type of commercially used NCM (e.g., LiNixCoyMnzO2), including code names or abbreviations (e.g., NCM811, N-NCM, SC-NCM) if applicable\n",
    "- The lithium source used for synthesizing the NCM\n",
    "- The synthesis method used for preparing the NCM samples (e.g., co-precipitation, sol-gel), including intermediate steps if reported\n",
    "- The crystallization method used (e.g., solid-state sintering, hydrothermal), and the specific final temperatures and durations used in the process\n",
    "- Whether any doping technique was applied to the CAM, and if so, which element(s) were doped\n",
    "- Whether any coating layer was applied to the CAM, and if so, what material was used for coating\n",
    "- The electrode composition, including the mass ratios of active material, conductive additive (e.g., Super P), and binder (e.g., PVDF)\n",
    "- The type of electrolyte solvent used (e.g., EC/DEC, EC/EMC/DEC), including volume or mass ratios if available\n",
    "- The lithium salt used in the electrolyte (e.g., LiPF6), and its concentration (e.g., 1 M or 1 mol/L)\n",
    "- Any additives used in the electrolyte, including their names and concentrations if reported\n",
    "- The mass loading (in mg/cm²) of the NCM active material used in the electrode\n",
    "- Particle size information from SEM or TEM images, including both secondary and primary particles if available\n",
    "- Descriptions of the particle shape observed in SEM or TEM data\n",
    "- Observations on particle distribution or uniformity reported in the SEM or TEM analysis\n",
    "- If a coating was applied, the reported properties and thickness of the coating layer as observed in SEM or TEM\n",
    "- The crystal structure and lattice characteristics (e.g., crystal plane spacing, presence of layered structure) from structural analysis\n",
    "- The voltage range and temperature used in electrochemical tests\n",
    "- The specific discharge capacities reported at various C-rates:\n",
    "  - 0.1C\n",
    "  - 0.2C\n",
    "  - 0.5C\n",
    "  - 1.0C\n",
    "  - 2.0C\n",
    "  - Any additional C-rate values and performance data reported\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'HumanMessage' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26196\\1824652286.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m graph.invoke(input={\n\u001b[0m\u001b[0;32m      2\u001b[0m     \"messages\": [HumanMessage(content=supervisor_question, name=\"Supervisor\")\n\u001b[0;32m      3\u001b[0m ]})\n",
      "\u001b[1;32mc:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   1934\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1935\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1936\u001b[1;33m         for chunk in self.stream(\n\u001b[0m\u001b[0;32m   1937\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1938\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1654\u001b[0m                 \u001b[1;31m# with channel updates applied only at the transition between steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1655\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1656\u001b[1;33m                     for _ in runner.tick(\n\u001b[0m\u001b[0;32m   1657\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1658\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\site-packages\\langgraph\\pregel\\runner.py\u001b[0m in \u001b[0;36mtick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;31m# panic on failure or timeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         _panic_or_proceed(\n\u001b[0m\u001b[0;32m    240\u001b[0m             \u001b[0mdone_futures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0mpanic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\site-packages\\langgraph\\pregel\\runner.py\u001b[0m in \u001b[0;36m_panic_or_proceed\u001b[1;34m(futs, timeout_exc_cls, panic)\u001b[0m\n\u001b[0;32m    537\u001b[0m             \u001b[1;31m# raise the exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpanic\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 539\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    540\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minflight\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[1;31m# if we got here means we timed out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\site-packages\\langgraph\\pregel\\executor.py\u001b[0m in \u001b[0;36mdone\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mGraphBubbleUp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;31m# This exception is an interruption signal, not an error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m                 \u001b[1;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\concurrent\\futures\\thread.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\site-packages\\langgraph\\pregel\\retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;31m# run the task\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\site-packages\\langgraph\\utils\\runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    406\u001b[0m                 )\n\u001b[0;32m    407\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m                     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\site-packages\\langgraph\\utils\\runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26196\\216810082.py\u001b[0m in \u001b[0;36magent_node\u001b[1;34m(state, agent, name)\u001b[0m\n\u001b[0;32m      8\u001b[0m     return {\n\u001b[0;32m      9\u001b[0m         \"messages\":  [\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mHumanMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magent_response\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"messages\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         ]\n\u001b[0;32m     12\u001b[0m     }\n",
      "\u001b[1;31mTypeError\u001b[0m: 'HumanMessage' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "graph.invoke(input={\n",
    "    \"messages\": [HumanMessage(content=supervisor_question, name=\"Supervisor\")]\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voltai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
