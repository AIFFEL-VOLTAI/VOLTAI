{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "## retriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores.base import VectorStoreRetriever\n",
    "\n",
    "## tool\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "## agent\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "## Nodes and Edges\n",
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "## Graph\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "## Response\n",
    "import pprint\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "\n",
    "# from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# \n",
    "# from langchain_core.messages import BaseMessage, FunctionMessage, HumanMessage\n",
    "# from langchain.tools.render import format_tool_to_openai_function\n",
    "# from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Key Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_if_undefined(var: str):\n",
    "    # 주어진 환경 변수가 설정되어 있지 않다면 사용자에게 입력을 요청하여 설정합니다.\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "\n",
    "# OPENAI_API_KEY 환경 변수가 설정되어 있지 않으면 사용자에게 입력을 요청합니다.\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")\n",
    "# LANGCHAIN_API_KEY 환경 변수가 설정되어 있지 않으면 사용자에게 입력을 요청합니다.\n",
    "_set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# LangSmith 추적 기능을 활성화합니다. (선택적)\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Multi-agent Collaboration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"../참고논문_1.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retriever(검색기) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_file(file: str) -> VectorStoreRetriever:\n",
    "    \"\"\"문서를 청크 단위로 분할하고 임베딩 모델(text-embedding-ada-002)을 통해 임베딩하여 vector store에 저장합니다. 이후 vector store를 기반으로 검색하는 객체를 생성합니다. \n",
    "\n",
    "    Args:\n",
    "        file (str): pdf 문서 경로\n",
    "\n",
    "    Returns:\n",
    "        VectorStoreRetriever: 검색기 \n",
    "    \"\"\"\n",
    "    \n",
    "    ## 긴 텍스트를 작은 청크로 나누는 데 사용되는 클래스\n",
    "    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(       \n",
    "        chunk_size=500,         ## 최대 청크 길이 정의\n",
    "        chunk_overlap=100,      ## 청크 간 겹침 길이 정의\n",
    "        separators=[\"\\n\\n\"]     ## 텍스트를 나눌 때 사용할 구분자를 지정 (문단)\n",
    "    )\n",
    "    \n",
    "    ## PDF 파일 불러오기\n",
    "    loader = PyPDFLoader(f\"{file}\")\n",
    "    docs = loader.load_and_split(text_splitter=splitter)\n",
    "    \n",
    "    ## Embedding 생성 및 vector store에 저장\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_store = FAISS.from_documents(\n",
    "        documents=docs,         ## 벡터 저장소에 추가할 문서 리스트\n",
    "        embedding=embeddings    ## 사용할 임베딩 함수\n",
    "    )\n",
    "    \n",
    "    ## 검색기로 변환: 현재 벡터 저장소를 기반으로 VectorStoreRetriever 객체를 생성하는 기능을 제공\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\"    ## 어떻게 검색할 것인지? default가 유사도\n",
    "    )\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = embedding_file(file=input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 논문에 대한 정보를 검색하고 반환하는 도구를 생성합니다.\n",
    "tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_papers\",\n",
    "    \"Search and return information about papers.\",\n",
    ")\n",
    "\n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghckd\\AppData\\Local\\Temp\\ipykernel_3616\\2394088372.py:2: LangGraphDeprecationWarning: ToolExecutor is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
      "  tool_executor = ToolExecutor(tools)\n"
     ]
    }
   ],
   "source": [
    "# 도구들을 실행할 ToolExecutor 객체를 생성합니다.\n",
    "tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    # AgentState 클래스는 메시지 시퀀스를 포함하는 타입 딕셔너리입니다.\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes and Edges "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_retrieve(state):\n",
    "    \"\"\"\n",
    "    에이전트가 더 많은 정보를 검색해야 하는지 또는 프로세스를 종료해야 하는지 결정합니다.\n",
    "\n",
    "    이 함수는 상태의 마지막 메시지에서 함수 호출을 확인합니다. 함수 호출이 있으면 정보 검색 프로세스를 계속합니다. 그렇지 않으면 프로세스를 종료합니다.\n",
    "\n",
    "    Args:\n",
    "        state (messages): 현재 상태\n",
    "\n",
    "    Returns:\n",
    "        str: 검색 프로세스를 \"계속\"하거나 \"종료\"하는 결정\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---DECIDE TO RETRIEVE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # 함수 호출이 없으면 종료합니다.\n",
    "    if \"function_call\" not in last_message.additional_kwargs:\n",
    "        print(\"---DECISION: DO NOT RETRIEVE / DONE---\")\n",
    "        return \"end\"\n",
    "    # 그렇지 않으면 함수 호출이 있으므로 계속합니다.\n",
    "    else:\n",
    "        print(\"---DECISION: RETRIEVE---\")\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    검색된 문서가 질문과 관련이 있는지 여부를 결정합니다.\n",
    "\n",
    "    Args:\n",
    "        state (messages): 현재 상태\n",
    "\n",
    "    Returns:\n",
    "        str: 문서가 관련이 있는지 여부에 대한 결정\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK RELEVANCE---\")\n",
    "\n",
    "    # 데이터 모델\n",
    "    class Grade(BaseModel):\n",
    "        \"\"\"관련성 검사를 위한 이진 점수.\"\"\"\n",
    "\n",
    "        binary_score: str = Field(description=\"'yes' 또는 'no'의 관련성 점수\")\n",
    "\n",
    "    # LLM\n",
    "    model = ChatOpenAI(\n",
    "        temperature=0, \n",
    "        model=\"gpt-4o\", \n",
    "        streaming=True\n",
    "    )\n",
    "\n",
    "    # 도구\n",
    "    grade_tool = convert_to_openai_tool(Grade)\n",
    "\n",
    "    # 도구와 강제 호출을 사용한 LLM\n",
    "    llm_with_tool = model.bind(\n",
    "        tools=[grade_tool],\n",
    "        # tool_choice={\"type\": \"function\", \"function\": {\"name\": \"grade\"}},\n",
    "    )\n",
    "\n",
    "    # 파서\n",
    "    parser_tool = PydanticToolsParser(tools=[Grade])\n",
    "\n",
    "    # 프롬프트\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # 체인\n",
    "    chain = prompt | llm_with_tool | parser_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    docs = messages[-1].content\n",
    "\n",
    "    score = chain.invoke({\"question\": question, \"context\": docs})\n",
    "\n",
    "    grade = score[0].binary_score\n",
    "\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        return \"yes\"\n",
    "\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        return \"no\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    도구를 사용하여 검색을 실행합니다.\n",
    "\n",
    "    Args:\n",
    "        state (messages): 현재 상태\n",
    "\n",
    "    Returns:\n",
    "        dict: 검색된 문서가 추가된 업데이트된 상태\n",
    "    \"\"\"\n",
    "    print(\"---EXECUTE RETRIEVAL---\")\n",
    "    messages = state[\"messages\"]\n",
    "    # 계속 조건을 기반으로 마지막 메시지가 함수 호출을 포함하고 있음을 알 수 있습니다.\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    if \"function_call\" not in last_message.additional_kwargs:\n",
    "        print(\"---No function call in last message---\")\n",
    "        return {\"messages\": messages}\n",
    "    \n",
    "    # 함수 호출에서 ToolInvocation을 구성합니다.\n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "        tool_input=json.loads(\n",
    "            last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "        ),\n",
    "    )\n",
    "    # 도구 실행자를 호출하고 응답을 받습니다.\n",
    "    response = tool_executor.invoke(action)\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "\n",
    "    # 이것은 기존 목록에 추가될 것이므로 리스트를 반환합니다.\n",
    "    return {\"messages\": [function_message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def agent(state):\n",
    "#     \"\"\"\n",
    "#     현재 상태를 기반으로 에이전트 모델을 호출하여 응답을 생성합니다. 질문에 따라 검색 도구를 사용하여 검색을 결정하거나 단순히 종료합니다.\n",
    "\n",
    "#     Args:\n",
    "#         state (messages): 현재 상태\n",
    "\n",
    "#     Returns:\n",
    "#         dict: 메시지에 에이전트 응답이 추가된 업데이트된 상태\n",
    "#     \"\"\"\n",
    "#     print(\"---CALL AGENT---\")\n",
    "#     messages = state[\"messages\"]\n",
    "#     model = ChatOpenAI(\n",
    "#         temperature=0, \n",
    "#         streaming=True,\n",
    "#         model=\"gpt-4o\"\n",
    "#         )\n",
    "#     functions = [format_tool_to_openai_function(t) for t in tools]\n",
    "#     model = model.bind_functions(functions)\n",
    "#     response = model.invoke(messages)\n",
    "#     # 이것은 기존 목록에 추가될 것이므로 리스트를 반환합니다.\n",
    "#     return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    질문을 변형하여 더 나은 질문을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        state (messages): 현재 상태\n",
    "\n",
    "    Returns:\n",
    "        dict: 재구성된 질문이 추가된 업데이트된 상태\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # 평가자\n",
    "    model = ChatOpenAI(\n",
    "        temperature=0, model=\"gpt-4o\", streaming=True)\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    \"\"\"\n",
    "    답변 생성\n",
    "\n",
    "    Args:\n",
    "        state (messages): 현재 상태\n",
    "\n",
    "    Returns:\n",
    "         dict: 재구성된 질문이 추가된 업데이트된 상태\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    # 프롬프트\n",
    "    prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Based on the following document, please provide an answer to the given question.\n",
    "\n",
    "    Document:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # LLM\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4o\",\n",
    "                     temperature=0, streaming=True)\n",
    "    print(\"-----------\")\n",
    "    print(docs)\n",
    "    # 후처리\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # 체인\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # 실행\n",
    "    response = rag_chain.invoke({\"context\": format_docs(docs), \"question\": question})\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1705fa1d290>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# langgraph.graph에서 StateGraph와 END를 가져옵니다.\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 순환할 노드들을 정의합니다.\n",
    "workflow.add_node(\"retrieve\", retrieve)  # 정보 검색 노드를 추가합니다.\n",
    "# workflow.add_node(\"agent\", agent)  # 에이전트 노드를 추가합니다.\n",
    "workflow.add_node(\"generate\", generate)  # 정보 생성 노드를 추가합니다.\n",
    "workflow.add_node(\"rewrite\", rewrite)  # 정보 재작성 노드를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이전트 노드 호출하여 검색 여부 결정\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "\n",
    "# 검색 후 생성 단계로 이동\n",
    "workflow.add_edge(\"retrieve\", \"generate\")\n",
    "\n",
    "# # 검색 여부 결정 노드를 직접 추가\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"retrieve\",  # 검색 후 관련성을 평가\n",
    "#     should_retrieve,  # 검색 계속 여부를 결정\n",
    "#     {\n",
    "#         \"continue\": \"generate\",  # 계속 검색\n",
    "#         \"end\": END,             # 종료\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# 문서 평가 노드\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_documents,\n",
    "    {\n",
    "        \"yes\": END,  # 문서가 관련 있으면 생성\n",
    "        \"no\": \"rewrite\",    # 문서가 관련 없으면 재작성\n",
    "    },\n",
    ")\n",
    "\n",
    "# 응답 생성 후 종료\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# 질문 수정 후 다시 검색\n",
    "workflow.add_edge(\"rewrite\", \"retrieve\")\n",
    "\n",
    "# 컴파일\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---EXECUTE RETRIEVAL---\n",
      "---No function call in last message---\n",
      "{'retrieve': {'messages': [HumanMessage(content='Below are instructions for filling out 23 items by referring to the examples. The values shown to the right of the colon (“:”) are examples; please delete them after reviewing and rewrite them with the values found in the PDF. If any item is not mentioned in the PDF, do not remove it—write “None.”\\n1. Electrode (only coin cell)\\n1.1 Cathode active material: NCM-622\\n1.2 Lithium source: LiOH\\n1.3 Nickel supplied during the co-precipitation process of the precursor: NiSO4·6H2O\\n1.4 Cobalt supplied during the co-precipitation process of the precursor: CoSO4·7H2O\\n1.5 Manganese supplied during the co-precipitation process of the precursor: MnSO4·H2O\\n1.6 Co-precipitation solution: NaOH, 4M\\n1.7 Crystallization method (Hydrothermal or Sintering): Hydrothermal\\n1.8 Crystallization temperature: 100°C\\n1.9 Crystallization time: 12 hr\\n1.10 Active material : Conductive additive : Binder ratio: 90 : 5 : 5\\n1.11 Electrolyte: LiPF6 (EC, EMC, DEC mixture in a 1:1:1 volume ratio)\\n1.12 Doping: Zr4+ doping\\n1.13 Coating: ZrO2 coating\\n1.14 Additive: FEC 10% addition\\n1.15 Electrode thickness: 100 µm\\n1.16 only Cathode Electrode diameter: 14π\\n1.17 Loading density: 0.005 g/cm^2\\n1.18 Commercial NCM (check if specified in the paper): No\\n2. Cathode Performance\\n2.1 Capacity at all C-rate, mAh/g (with electrode state; e.g., coated or uncoated) : 214.5 mAh/g\\n2.2 Voltage range: 2.8–4.3 V\\n2.3 Temperature: Room temperature and 55°C\\n3. Cathode Equipment\\n3.1 Explanation of SEM results (indicate figure numbers as well):\\nex) Fig. 2a, b;the NCM-622 seems to have more or less a spherical morphology with a diameter of 3–5 µm, composed of densely packed primary parti-cles\\n3.2 Explanation of TEM results: None', additional_kwargs={}, response_metadata={})]}}\n",
      "\"Output from node 'retrieve':\"\n",
      "'---'\n",
      "{ 'messages': [ HumanMessage(content='Below are instructions for filling out 23 items by referring to the examples. The values shown to the right of the colon (“:”) are examples; please delete them after reviewing and rewrite them with the values found in the PDF. If any item is not mentioned in the PDF, do not remove it—write “None.”\\n1. Electrode (only coin cell)\\n1.1 Cathode active material: NCM-622\\n1.2 Lithium source: LiOH\\n1.3 Nickel supplied during the co-precipitation process of the precursor: NiSO4·6H2O\\n1.4 Cobalt supplied during the co-precipitation process of the precursor: CoSO4·7H2O\\n1.5 Manganese supplied during the co-precipitation process of the precursor: MnSO4·H2O\\n1.6 Co-precipitation solution: NaOH, 4M\\n1.7 Crystallization method (Hydrothermal or Sintering): Hydrothermal\\n1.8 Crystallization temperature: 100°C\\n1.9 Crystallization time: 12 hr\\n1.10 Active material : Conductive additive : Binder ratio: 90 : 5 : 5\\n1.11 Electrolyte: LiPF6 (EC, EMC, DEC mixture in a 1:1:1 volume ratio)\\n1.12 Doping: Zr4+ doping\\n1.13 Coating: ZrO2 coating\\n1.14 Additive: FEC 10% addition\\n1.15 Electrode thickness: 100 µm\\n1.16 only Cathode Electrode diameter: 14π\\n1.17 Loading density: 0.005 g/cm^2\\n1.18 Commercial NCM (check if specified in the paper): No\\n2. Cathode Performance\\n2.1 Capacity at all C-rate, mAh/g (with electrode state; e.g., coated or uncoated) : 214.5 mAh/g\\n2.2 Voltage range: 2.8–4.3 V\\n2.3 Temperature: Room temperature and 55°C\\n3. Cathode Equipment\\n3.1 Explanation of SEM results (indicate figure numbers as well):\\nex) Fig. 2a, b;the NCM-622 seems to have more or less a spherical morphology with a diameter of 3–5 µm, composed of densely packed primary parti-cles\\n3.2 Explanation of TEM results: None', additional_kwargs={}, response_metadata={})]}\n",
      "'\\n---\\n'\n",
      "---GENERATE---\n",
      "-----------\n",
      "Below are instructions for filling out 23 items by referring to the examples. The values shown to the right of the colon (“:”) are examples; please delete them after reviewing and rewrite them with the values found in the PDF. If any item is not mentioned in the PDF, do not remove it—write “None.”\n",
      "1. Electrode (only coin cell)\n",
      "1.1 Cathode active material: NCM-622\n",
      "1.2 Lithium source: LiOH\n",
      "1.3 Nickel supplied during the co-precipitation process of the precursor: NiSO4·6H2O\n",
      "1.4 Cobalt supplied during the co-precipitation process of the precursor: CoSO4·7H2O\n",
      "1.5 Manganese supplied during the co-precipitation process of the precursor: MnSO4·H2O\n",
      "1.6 Co-precipitation solution: NaOH, 4M\n",
      "1.7 Crystallization method (Hydrothermal or Sintering): Hydrothermal\n",
      "1.8 Crystallization temperature: 100°C\n",
      "1.9 Crystallization time: 12 hr\n",
      "1.10 Active material : Conductive additive : Binder ratio: 90 : 5 : 5\n",
      "1.11 Electrolyte: LiPF6 (EC, EMC, DEC mixture in a 1:1:1 volume ratio)\n",
      "1.12 Doping: Zr4+ doping\n",
      "1.13 Coating: ZrO2 coating\n",
      "1.14 Additive: FEC 10% addition\n",
      "1.15 Electrode thickness: 100 µm\n",
      "1.16 only Cathode Electrode diameter: 14π\n",
      "1.17 Loading density: 0.005 g/cm^2\n",
      "1.18 Commercial NCM (check if specified in the paper): No\n",
      "2. Cathode Performance\n",
      "2.1 Capacity at all C-rate, mAh/g (with electrode state; e.g., coated or uncoated) : 214.5 mAh/g\n",
      "2.2 Voltage range: 2.8–4.3 V\n",
      "2.3 Temperature: Room temperature and 55°C\n",
      "3. Cathode Equipment\n",
      "3.1 Explanation of SEM results (indicate figure numbers as well):\n",
      "ex) Fig. 2a, b;the NCM-622 seems to have more or less a spherical morphology with a diameter of 3–5 µm, composed of densely packed primary parti-cles\n",
      "3.2 Explanation of TEM results: None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3616\\1320698236.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m }\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# app.stream을 통해 입력된 메시지에 대한 출력을 스트리밍합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# 출력된 결과에서 키와 값을 순회합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1654\u001b[0m                 \u001b[1;31m# with channel updates applied only at the transition between steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1655\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1656\u001b[1;33m                     for _ in runner.tick(\n\u001b[0m\u001b[0;32m   1657\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1658\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\site-packages\\langgraph\\pregel\\runner.py\u001b[0m in \u001b[0;36mtick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                 run_with_retry(\n\u001b[0m\u001b[0;32m    168\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\site-packages\\langgraph\\pregel\\retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;31m# run the task\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\site-packages\\langgraph\\utils\\runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    406\u001b[0m                 )\n\u001b[0;32m    407\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m                     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\site-packages\\langgraph\\utils\\runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3616\\3989799568.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# 실행\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrag_chain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"context\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mformat_docs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"question\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mquestion\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"messages\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3616\\3989799568.py\u001b[0m in \u001b[0;36mformat_docs\u001b[1;34m(docs)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# 후처리\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mformat_docs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"\\n\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# 체인\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3616\\3989799568.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# 후처리\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mformat_docs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"\\n\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# 체인\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "# HumanMessage 객체를 사용하여 질문 메시지를 정의합니다.\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"\"\"Below are instructions for filling out 23 items by referring to the examples. The values shown to the right of the colon (“:”) are examples; please delete them after reviewing and rewrite them with the values found in the PDF. If any item is not mentioned in the PDF, do not remove it—write “None.”\n",
    "1. Electrode (only coin cell)\n",
    "1.1 Cathode active material: NCM-622\n",
    "1.2 Lithium source: LiOH\n",
    "1.3 Nickel supplied during the co-precipitation process of the precursor: NiSO4·6H2O\n",
    "1.4 Cobalt supplied during the co-precipitation process of the precursor: CoSO4·7H2O\n",
    "1.5 Manganese supplied during the co-precipitation process of the precursor: MnSO4·H2O\n",
    "1.6 Co-precipitation solution: NaOH, 4M\n",
    "1.7 Crystallization method (Hydrothermal or Sintering): Hydrothermal\n",
    "1.8 Crystallization temperature: 100°C\n",
    "1.9 Crystallization time: 12 hr\n",
    "1.10 Active material : Conductive additive : Binder ratio: 90 : 5 : 5\n",
    "1.11 Electrolyte: LiPF6 (EC, EMC, DEC mixture in a 1:1:1 volume ratio)\n",
    "1.12 Doping: Zr4+ doping\n",
    "1.13 Coating: ZrO2 coating\n",
    "1.14 Additive: FEC 10% addition\n",
    "1.15 Electrode thickness: 100 µm\n",
    "1.16 only Cathode Electrode diameter: 14π\n",
    "1.17 Loading density: 0.005 g/cm^2\n",
    "1.18 Commercial NCM (check if specified in the paper): No\n",
    "2. Cathode Performance\n",
    "2.1 Capacity at all C-rate, mAh/g (with electrode state; e.g., coated or uncoated) : 214.5 mAh/g\n",
    "2.2 Voltage range: 2.8–4.3 V\n",
    "2.3 Temperature: Room temperature and 55°C\n",
    "3. Cathode Equipment\n",
    "3.1 Explanation of SEM results (indicate figure numbers as well):\n",
    "ex) Fig. 2a, b;the NCM-622 seems to have more or less a spherical morphology with a diameter of 3–5 µm, composed of densely packed primary parti-cles\n",
    "3.2 Explanation of TEM results: None\"\"\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "# app.stream을 통해 입력된 메시지에 대한 출력을 스트리밍합니다.\n",
    "for output in app.stream(inputs):\n",
    "    print(output)\n",
    "    # 출력된 결과에서 키와 값을 순회합니다.\n",
    "    for key, value in output.items():\n",
    "        # 노드의 이름과 해당 노드에서 나온 출력을 출력합니다.\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(\"---\")\n",
    "        # 출력 값을 예쁘게 출력합니다.\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "    # 각 출력 사이에 구분선을 추가합니다.\n",
    "    pprint.pprint(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='어떤 논문에서 키워드를 추출해드릴까요? 논문의 제목이나 주제를 알려주시면 도와드리겠습니다.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782'}, id='run-afd99121-0896-4d21-8c8b-6b31cf0f12fb-0')]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(value[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voltai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
