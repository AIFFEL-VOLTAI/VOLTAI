{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os \n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "## retriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores.base import VectorStoreRetriever\n",
    "\n",
    "## tool\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "## agent\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict, Literal\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "## Nodes and Edges\n",
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict, List\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage, HumanMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "## web retriever\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "## Graph\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "## Response\n",
    "import pprint\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "# , MessagesPlaceholder\n",
    "# from langchain_core.messages import BaseMessage, FunctionMessage, HumanMessage\n",
    "# from langchain.tools.render import format_tool_to_openai_function\n",
    "# from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Key Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_if_undefined(var: str):\n",
    "    # ì£¼ì–´ì§„ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šë‹¤ë©´ ì‚¬ìš©ìì—ê²Œ ì…ë ¥ì„ ìš”ì²­í•˜ì—¬ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "\n",
    "# OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ì…ë ¥ì„ ìš”ì²­í•©ë‹ˆë‹¤.\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")\n",
    "# LANGCHAIN_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ì…ë ¥ì„ ìš”ì²­í•©ë‹ˆë‹¤.\n",
    "_set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "# TAVILY_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ì…ë ¥ì„ ìš”ì²­í•©ë‹ˆë‹¤.\n",
    "_set_if_undefined(\"TAVILY_API_KEY\")\n",
    "\n",
    "# LangSmith ì¶”ì  ê¸°ëŠ¥ì„ í™œì„±í™”í•©ë‹ˆë‹¤. (ì„ íƒì )\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Multi-agent Collaboration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"../ì°¸ê³ ë…¼ë¬¸_1.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retriever(ê²€ìƒ‰ê¸°) ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_file(file: str) -> VectorStoreRetriever:\n",
    "    \"\"\"ë¬¸ì„œë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ê³  ì„ë² ë”© ëª¨ë¸(text-embedding-ada-002)ì„ í†µí•´ ì„ë² ë”©í•˜ì—¬ vector storeì— ì €ì¥í•©ë‹ˆë‹¤. ì´í›„ vector storeë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. \n",
    "\n",
    "    Args:\n",
    "        file (str): pdf ë¬¸ì„œ ê²½ë¡œ\n",
    "\n",
    "    Returns:\n",
    "        VectorStoreRetriever: ê²€ìƒ‰ê¸° \n",
    "    \"\"\"\n",
    "    \n",
    "    ## ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ„ëŠ” ë° ì‚¬ìš©ë˜ëŠ” í´ë˜ìŠ¤\n",
    "    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(       \n",
    "        chunk_size=500,         ## ìµœëŒ€ ì²­í¬ ê¸¸ì´ ì •ì˜\n",
    "        chunk_overlap=100,      ## ì²­í¬ ê°„ ê²¹ì¹¨ ê¸¸ì´ ì •ì˜\n",
    "        separators=[\"\\n\\n\"]     ## í…ìŠ¤íŠ¸ë¥¼ ë‚˜ëˆŒ ë•Œ ì‚¬ìš©í•  êµ¬ë¶„ìë¥¼ ì§€ì • (ë¬¸ë‹¨)\n",
    "    )\n",
    "    \n",
    "    ## PDF íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    loader = PyPDFLoader(f\"{file}\")\n",
    "    docs = loader.load_and_split(text_splitter=splitter)\n",
    "    \n",
    "    ## Embedding ìƒì„± ë° vector storeì— ì €ì¥\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_store = FAISS.from_documents(\n",
    "        documents=docs,         ## ë²¡í„° ì €ì¥ì†Œì— ì¶”ê°€í•  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸\n",
    "        embedding=embeddings    ## ì‚¬ìš©í•  ì„ë² ë”© í•¨ìˆ˜\n",
    "    )\n",
    "    \n",
    "    ## ê²€ìƒ‰ê¸°ë¡œ ë³€í™˜: í˜„ì¬ ë²¡í„° ì €ì¥ì†Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ VectorStoreRetriever ê°ì²´ë¥¼ ìƒì„±í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µ\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\"    ## ì–´ë–»ê²Œ ê²€ìƒ‰í•  ê²ƒì¸ì§€? defaultê°€ ìœ ì‚¬ë„\n",
    "    )\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = embedding_file(file=input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì¿¼ë¦¬ ë¼ìš°íŒ…ê³¼ ë¬¸ì„œ í‰ê°€\n",
    "- ì¿¼ë¦¬ ë¼ìš°íŒ…: ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì •ë³´ ì†ŒìŠ¤ë¡œ ë¼ìš°íŒ…í•œë‹¤. \n",
    "- ë¬¸ì„œ í‰ê°€: ê²€ìƒ‰ëœ ë¬¸ì„œì˜ í’ˆì§ˆê³¼ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ì—¬ ìµœì¢… ê²°ê³¼ì˜ ì •í™•ì„±ì„ ë†’ì¸ë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë°ì´í„° ì†ŒìŠ¤ë¡œ ë¼ìš°íŒ…í•˜ëŠ” ë°ì´í„° ëª¨ë¸\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    # ë°ì´í„° ì†ŒìŠ¤ ì„ íƒì„ ìœ„í•œ ë¦¬í„°ëŸ´ íƒ€ì… í•„ë“œ\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to web search or a vectorstore.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM ì´ˆê¸°í™” ë° í•¨ìˆ˜ í˜¸ì¶œì„ í†µí•œ êµ¬ì¡°í™”ëœ ì¶œë ¥ ìƒì„±\n",
    "llm_roouter = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "structured_llm_router = llm_roouter.with_structured_output(RouteQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ì§ˆë¬¸ì„ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "system = \"\"\"You are an expert in extracting key variables and concepts from scientific literature on battery technology.\n",
    "Your task is to analyze user-provided questions and identify the specific variables, parameters, or concepts related to battery research from the input text.\n",
    "\n",
    "The input text will consist of technical content, including battery performance metrics, materials, and experimental results.\"\"\"\n",
    "\n",
    "# Routing ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ê³¼ êµ¬ì¡°í™”ëœ LLM ë¼ìš°í„°ë¥¼ ê²°í•©í•˜ì—¬ ì§ˆë¬¸ ë¼ìš°í„° ìƒì„±\n",
    "question_router = route_prompt | structured_llm_router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='vectorstore'\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    question_router.invoke(\n",
    "        {\"question\": \"ì†Œì¬ë“¤ì€ ëª‡ë„ì—ì„œ ê°€ê³µë˜ì—ˆì–´?\"}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê²€ìƒ‰ í‰ê°€ê¸° (Retrieval Grader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì„œ í‰ê°€ë¥¼ ìœ„í•œ ë°ì´í„° ëª¨ë¸ ì •ì˜\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM ì´ˆê¸°í™” ë° í•¨ìˆ˜ í˜¸ì¶œì„ í†µí•œ êµ¬ì¡°í™”ëœ ì¶œë ¥ ìƒì„±\n",
    "llm_retrieval_grader = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "structured_llm_grader = llm_retrieval_grader.with_structured_output(GradeDocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ì§ˆë¬¸ì„ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ë¬¸ì„œ ê²€ìƒ‰ê²°ê³¼ í‰ê°€ê¸° ìƒì„±\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "# ì‚¬ìš©ì ì§ˆë¬¸ ì„¤ì •\n",
    "question = \"ì‚¼ì„±ì „ìê°€ ë§Œë“  ìƒì„±í˜• AI ì˜ ì´ë¦„ì€?\"\n",
    "\n",
    "# ì§ˆë¬¸ì— ëŒ€í•œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
    "docs = retriever.invoke(question)\n",
    "\n",
    "# ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°\n",
    "retrieved_doc = docs[1].page_content\n",
    "\n",
    "# í‰ê°€ ê²°ê³¼ ì¶œë ¥\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": retrieved_doc}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹µë³€ ìƒì„±ì„ ìœ„í•œ RAG ì²´ì¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Based on the following document, please provide an answer to the given question.\n",
    "\n",
    "    Document:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm_generator = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# ë¬¸ì„œ í¬ë§·íŒ… í•¨ìˆ˜\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f'<document><content>{doc.page_content}</content><source>{doc.metadata[\"source\"]}</source><page>{doc.metadata[\"page\"]+1}</page></document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# RAG ì²´ì¸ ìƒì„±\n",
    "rag_chain = prompt | llm_generator | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹µë³€ì˜ í• ë£¨ì‹œë„¤ì´ì…˜ checker ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í• ë£¨ì‹œë„¤ì´ì…˜ ì²´í¬ë¥¼ ìœ„í•œ ë°ì´í„° ëª¨ë¸ ì •ì˜\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•¨ìˆ˜ í˜¸ì¶œì„ í†µí•œ LLM ì´ˆê¸°í™”\n",
    "llm_halluci_checker = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "structured_llm_halluci_checker = llm_halluci_checker.with_structured_output(GradeHallucinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n",
    "    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# í™˜ê° í‰ê°€ê¸° ìƒì„±\n",
    "hallucination_grader = hallucination_prompt | structured_llm_halluci_checker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹µë³€ì˜ relevant checker ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary scoring to evaluate the appropriateness of answers to questions\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Indicate 'yes' or 'no' whether the answer solves the question\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•¨ìˆ˜ í˜¸ì¶œì„ í†µí•œ LLM ì´ˆê¸°í™”\n",
    "llm_grader = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "structured_llm_grader = llm_grader.with_structured_output(GradeAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n \n",
    "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ê³¼ êµ¬ì¡°í™”ëœ LLM í‰ê°€ê¸°ë¥¼ ê²°í•©í•˜ì—¬ ë‹µë³€ í‰ê°€ê¸° ìƒì„±\n",
    "answer_grader = answer_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í€´ë¦¬ ì¬ì‘ì„± (Query Rewriter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM ì´ˆê¸°í™”\n",
    "llm_rewriter = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Rewriter í”„ë¡¬í”„íŠ¸ ì •ì˜(ììœ ë¡­ê²Œ ìˆ˜ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤)\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "\n",
    "# Query Rewriter í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Query Rewriter ìƒì„±\n",
    "question_rewriter = re_write_prompt | llm_rewriter | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì›¹ ê²€ìƒ‰ ë„êµ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›¹ ê²€ìƒ‰ ë„êµ¬ ìƒì„±\n",
    "web_search_tool = TavilySearch(max_results=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphState ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë˜í”„ì˜ ìƒíƒœ ì •ì˜\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    ê·¸ë˜í”„ì˜ ìƒíƒœë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë°ì´í„° ëª¨ë¸\n",
    "\n",
    "    Attributes:\n",
    "        question: ì§ˆë¬¸\n",
    "        generation: LLM ìƒì„±ëœ ë‹µë³€\n",
    "        documents: ë„íë¨¼í‹‘ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "\n",
    "    question: Annotated[str, \"User question\"]\n",
    "    generation: Annotated[str, \"LLM generated answer\"]\n",
    "    documents: Annotated[List[str], \"List of documents\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì„œ ê²€ìƒ‰ ë…¸ë“œ\n",
    "def retrieve(state):\n",
    "    print(\"==== [RETRIEVE] ====\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "# ë‹µë³€ ìƒì„± ë…¸ë“œ\n",
    "def generate(state):\n",
    "    print(\"==== [GENERATE] ====\")\n",
    "    # ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG ë‹µë³€ ìƒì„±\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ ë…¸ë“œ\n",
    "def grade_documents(state):\n",
    "    print(\"==== [CHECK DOCUMENT RELEVANCE TO QUESTION] ====\")\n",
    "    # ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # ê° ë¬¸ì„œì— ëŒ€í•œ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            # ê´€ë ¨ì„±ì´ ìˆëŠ” ë¬¸ì„œ ì¶”ê°€\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            # ê´€ë ¨ì„±ì´ ì—†ëŠ” ë¬¸ì„œëŠ” ê±´ë„ˆë›°ê¸°\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "\n",
    "# ì§ˆë¬¸ ì¬ì‘ì„± ë…¸ë“œ\n",
    "def transform_query(state):\n",
    "    print(\"==== [TRANSFORM QUERY] ====\")\n",
    "    # ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # ì§ˆë¬¸ ì¬ì‘ì„±\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "# ì›¹ ê²€ìƒ‰ ë…¸ë“œ\n",
    "def web_search(state):\n",
    "    print(\"==== [WEB SEARCH] ====\")\n",
    "    # ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # ì›¹ ê²€ìƒ‰ ìˆ˜í–‰\n",
    "    web_results = web_search_tool.invoke({\"query\": question})\n",
    "    web_results_docs = [\n",
    "        Document(\n",
    "            page_content=web_result[\"content\"],\n",
    "            metadata={\"source\": web_result[\"url\"]},\n",
    "        )\n",
    "        for web_result in web_results\n",
    "    ]\n",
    "\n",
    "    return {\"documents\": web_results_docs, \"question\": question}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§ˆë¬¸ ë¼ìš°íŒ… ë…¸ë“œ\n",
    "def route_question(state):\n",
    "    print(\"==== [ROUTE QUESTION] ====\")\n",
    "    # ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "    # ì§ˆë¬¸ ë¼ìš°íŒ…\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    # ì§ˆë¬¸ ë¼ìš°íŒ… ê²°ê³¼ì— ë”°ë¥¸ ë…¸ë“œ ë¼ìš°íŒ…\n",
    "    if source.datasource == \"web_search\":\n",
    "        print(\"==== [ROUTE QUESTION TO WEB SEARCH] ====\")\n",
    "        return \"web_search\"\n",
    "    elif source.datasource == \"vectorstore\":\n",
    "        print(\"==== [ROUTE QUESTION TO VECTORSTORE] ====\")\n",
    "        return \"vectorstore\"\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ ë…¸ë“œ\n",
    "def decide_to_generate(state):\n",
    "    print(\"==== [DECISION TO GENERATE] ====\")\n",
    "    # ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # ëª¨ë“  ë¬¸ì„œê°€ ê´€ë ¨ì„± ì—†ëŠ” ê²½ìš° ì§ˆë¬¸ ì¬ì‘ì„±\n",
    "        print(\n",
    "            \"==== [DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY] ====\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # ê´€ë ¨ì„± ìˆëŠ” ë¬¸ì„œê°€ ìˆëŠ” ê²½ìš° ë‹µë³€ ìƒì„±\n",
    "        print(\"==== [DECISION: GENERATE] ====\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def hallucination_check(state):\n",
    "    print(\"==== [CHECK HALLUCINATIONS] ====\")\n",
    "    # ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    # í™˜ê° í‰ê°€\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "\n",
    "    # Hallucination ì—¬ë¶€ í™•ì¸\n",
    "    if grade == \"yes\":\n",
    "        print(\"==== [DECISION: GENERATION IS GROUNDED IN DOCUMENTS] ====\")\n",
    "\n",
    "        # ë‹µë³€ì˜ ê´€ë ¨ì„±(Relevance) í‰ê°€\n",
    "        print(\"==== [GRADE GENERATED ANSWER vs QUESTION] ====\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "\n",
    "        # ê´€ë ¨ì„± í‰ê°€ ê²°ê³¼ì— ë”°ë¥¸ ì²˜ë¦¬\n",
    "        if grade == \"yes\":\n",
    "            print(\"==== [DECISION: GENERATED ANSWER ADDRESSES QUESTION] ====\")\n",
    "            return \"relevant\"\n",
    "        else:\n",
    "            print(\"==== [DECISION: GENERATED ANSWER DOES NOT ADDRESS QUESTION] ====\")\n",
    "            return \"not relevant\"\n",
    "    else:\n",
    "        print(\"==== [DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY] ====\")\n",
    "        return \"hallucination\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import stream_graph, random_uuid, invoke_graph\n",
    "\n",
    "# config ì„¤ì •(ì¬ê·€ ìµœëŒ€ íšŸìˆ˜, thread_id)\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "inputs = GraphState(question=\"\"\"Below are instructions for filling out 23 items by referring to the examples. The values shown to the right of the colon (â€œ:â€) are examples; please delete them after reviewing and rewrite them with the values found in the PDF. If any item is not mentioned in the PDF, do not remove itâ€”write â€œNone.â€\n",
    "1. Electrode (only coin cell)\n",
    "1.1 Cathode active material: NCM-622\n",
    "1.2 Lithium source: LiOH\n",
    "1.3 Nickel supplied during the co-precipitation process of the precursor: NiSO4Â·6H2O\n",
    "1.4 Cobalt supplied during the co-precipitation process of the precursor: CoSO4Â·7H2O\n",
    "1.5 Manganese supplied during the co-precipitation process of the precursor: MnSO4Â·H2O\n",
    "1.6 Co-precipitation solution: NaOH, 4M\n",
    "1.7 Crystallization method (Hydrothermal or Sintering): Hydrothermal\n",
    "1.8 Crystallization temperature: 100Â°C\n",
    "1.9 Crystallization time: 12 hr\n",
    "1.10 Active material : Conductive additive : Binder ratio: 90 : 5 : 5\n",
    "1.11 Electrolyte: LiPF6 (EC, EMC, DEC mixture in a 1:1:1 volume ratio)\n",
    "1.12 Doping: Zr4+ doping\n",
    "1.13 Coating: ZrO2 coating\n",
    "1.14 Additive: FEC 10% addition\n",
    "1.15 Electrode thickness: 100 Âµm\n",
    "1.16 only Cathode Electrode diameter: 14Ï€\n",
    "1.17 Loading density: 0.005 g/cm^2\n",
    "1.18 Commercial NCM (check if specified in the paper): No\n",
    "2. Cathode Performance\n",
    "2.1 Capacity at all C-rate, mAh/g (with electrode state; e.g., coated or uncoated) : 214.5 mAh/g\n",
    "2.2 Voltage range: 2.8â€“4.3 V\n",
    "2.3 Temperature: Room temperature and 55Â°C\n",
    "3. Cathode Equipment\n",
    "3.1 Explanation of SEM results (indicate figure numbers as well):\n",
    "ex) Fig. 2a, b;the NCM-622 seems to have more or less a spherical morphology with a diameter of 3â€“5 Âµm, composed of densely packed primary parti-cles\n",
    "3.2 Explanation of TEM results: None\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mrelevance_check\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==== [RELEVANCE CHECK] ====\n",
      "yes\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mllm_answer\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "1. Electrode (only coin cell)\n",
      "1.1 Cathode active material: NCM622\n",
      "1.2 Lithium source: Li2CO3\n",
      "1.3 Nickel supplied during the co-precipitation process of the precursor: NiC4H6O4Â·4H2O\n",
      "1.4 Cobalt supplied during the co-precipitation process of the precursor: Co(NO3)2Â·6H2O\n",
      "1.5 Manganese supplied during the co-precipitation process of the precursor: MnC4H6O4Â·4H2O\n",
      "1.6 Co-precipitation solution: None\n",
      "1.7 Crystallization method (Hydrothermal or Sintering): Sintering\n",
      "1.8 Crystallization temperature: 600Â°C, 700Â°C, 800Â°C\n",
      "1.9 Crystallization time: 12 hr\n",
      "1.10 Active material : Conductive additive : Binder ratio: None\n",
      "1.11 Electrolyte: 1.2 M LiPF6 in EC-EMC (3:7 volume ratio) with 2 wt% VC\n",
      "1.12 Doping: None\n",
      "1.13 Coating: None\n",
      "1.14 Additive: None\n",
      "1.15 Electrode thickness: None\n",
      "1.16 only Cathode Electrode diameter: None\n",
      "1.17 Loading density: ~3 mg/cmÂ²\n",
      "1.18 Commercial NCM (check if specified in the paper): None\n",
      "\n",
      "2. Cathode Performance\n",
      "2.1 Capacity at all C-rate, mAh/g (with electrode state; e.g., coated or uncoated): Initial discharge capacities of 180.7, 206.8, and 195.3 mAh/g for NCM622-600, NCM622-700, and NCM622-800, respectively\n",
      "2.2 Voltage range: 2.8â€“4.5 V\n",
      "2.3 Temperature: 25Â°C\n",
      "\n",
      "3. Cathode Equipment\n",
      "3.1 Explanation of SEM results (indicate figure numbers as well): Fig. 4; SEM images show the morphology of the NCM622 samples, indicating a uniform particle distribution.\n",
      "3.2 Explanation of TEM results: None"
     ]
    }
   ],
   "source": [
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "stream_graph(\n",
    "    graph=app, \n",
    "    inputs=inputs, \n",
    "    config=config, \n",
    "    node_names=[\"relevance_check\", \"llm_answer\"]\n",
    ")\n",
    "outputs = app.get_state(config).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voltai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
