{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghckd\\anaconda3\\envs\\voltai\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os \n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "## retriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores.base import VectorStoreRetriever\n",
    "\n",
    "## tool\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "## agent\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict, Literal\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "## Nodes and Edges\n",
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict, List\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage, HumanMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "## web retriever\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "## Graph\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "## Response\n",
    "import pprint\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "# , MessagesPlaceholder\n",
    "# from langchain_core.messages import BaseMessage, FunctionMessage, HumanMessage\n",
    "# from langchain.tools.render import format_tool_to_openai_function\n",
    "# from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Key Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_if_undefined(var: str):\n",
    "    # 주어진 환경 변수가 설정되어 있지 않다면 사용자에게 입력을 요청하여 설정합니다.\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "\n",
    "# OPENAI_API_KEY 환경 변수가 설정되어 있지 않으면 사용자에게 입력을 요청합니다.\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")\n",
    "# LANGCHAIN_API_KEY 환경 변수가 설정되어 있지 않으면 사용자에게 입력을 요청합니다.\n",
    "_set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "# TAVILY_API_KEY 환경 변수가 설정되어 있지 않으면 사용자에게 입력을 요청합니다.\n",
    "_set_if_undefined(\"TAVILY_API_KEY\")\n",
    "\n",
    "# LangSmith 추적 기능을 활성화합니다. (선택적)\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Multi-agent Collaboration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"../참고논문_1.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retriever(검색기) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_file(file: str) -> VectorStoreRetriever:\n",
    "    \"\"\"문서를 청크 단위로 분할하고 임베딩 모델(text-embedding-ada-002)을 통해 임베딩하여 vector store에 저장합니다. 이후 vector store를 기반으로 검색하는 객체를 생성합니다. \n",
    "\n",
    "    Args:\n",
    "        file (str): pdf 문서 경로\n",
    "\n",
    "    Returns:\n",
    "        VectorStoreRetriever: 검색기 \n",
    "    \"\"\"\n",
    "    \n",
    "    ## 긴 텍스트를 작은 청크로 나누는 데 사용되는 클래스\n",
    "    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(       \n",
    "        chunk_size=500,         ## 최대 청크 길이 정의\n",
    "        chunk_overlap=100,      ## 청크 간 겹침 길이 정의\n",
    "        separators=[\"\\n\\n\"]     ## 텍스트를 나눌 때 사용할 구분자를 지정 (문단)\n",
    "    )\n",
    "    \n",
    "    ## PDF 파일 불러오기\n",
    "    loader = PyPDFLoader(f\"{file}\")\n",
    "    docs = loader.load_and_split(text_splitter=splitter)\n",
    "    \n",
    "    ## Embedding 생성 및 vector store에 저장\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_store = FAISS.from_documents(\n",
    "        documents=docs,         ## 벡터 저장소에 추가할 문서 리스트\n",
    "        embedding=embeddings    ## 사용할 임베딩 함수\n",
    "    )\n",
    "    \n",
    "    ## 검색기로 변환: 현재 벡터 저장소를 기반으로 VectorStoreRetriever 객체를 생성하는 기능을 제공\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\"    ## 어떻게 검색할 것인지? default가 유사도\n",
    "    )\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = embedding_file(file=input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 쿼리 라우팅과 문서 평가\n",
    "- 쿼리 라우팅: 사용자의 쿼리를 분석하여 적절한 정보 소스로 라우팅한다. \n",
    "- 문서 평가: 검색된 문서의 품질과 관련성을 평가하여 최종 결과의 정확성을 높인다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 쿼리를 가장 관련성 높은 데이터 소스로 라우팅하는 데이터 모델\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    # 데이터 소스 선택을 위한 리터럴 타입 필드\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to web search or a vectorstore.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 초기화 및 함수 호출을 통한 구조화된 출력 생성\n",
    "llm_roouter = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "structured_llm_router = llm_roouter.with_structured_output(RouteQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시스템 메시지와 사용자 질문을 포함한 프롬프트 템플릿 생성\n",
    "system = \"\"\"You are an expert in extracting key variables and concepts from scientific literature on battery technology.\n",
    "Your task is to analyze user-provided questions and identify the specific variables, parameters, or concepts related to battery research from the input text.\n",
    "\n",
    "The input text will consist of technical content, including battery performance metrics, materials, and experimental results.\"\"\"\n",
    "\n",
    "# Routing 을 위한 프롬프트 템플릿 생성\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿과 구조화된 LLM 라우터를 결합하여 질문 라우터 생성\n",
    "question_router = route_prompt | structured_llm_router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='vectorstore'\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    question_router.invoke(\n",
    "        {\"question\": \"소재들은 몇도에서 가공되었어?\"}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검색 평가기 (Retrieval Grader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 평가를 위한 데이터 모델 정의\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 초기화 및 함수 호출을 통한 구조화된 출력 생성\n",
    "llm_retrieval_grader = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "structured_llm_grader = llm_retrieval_grader.with_structured_output(GradeDocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시스템 메시지와 사용자 질문을 포함한 프롬프트 템플릿 생성\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 문서 검색결과 평가기 생성\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "# 사용자 질문 설정\n",
    "question = \"삼성전자가 만든 생성형 AI 의 이름은?\"\n",
    "\n",
    "# 질문에 대한 관련 문서 검색\n",
    "docs = retriever.invoke(question)\n",
    "\n",
    "# 검색된 문서의 내용 가져오기\n",
    "retrieved_doc = docs[1].page_content\n",
    "\n",
    "# 평가 결과 출력\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": retrieved_doc}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 답변 생성을 위한 RAG 체인 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 설정\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Based on the following document, please provide an answer to the given question.\n",
    "\n",
    "    Document:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "# LLM 초기화\n",
    "llm_generator = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# 문서 포맷팅 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f'<document><content>{doc.page_content}</content><source>{doc.metadata[\"source\"]}</source><page>{doc.metadata[\"page\"]+1}</page></document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# RAG 체인 생성\n",
    "rag_chain = prompt | llm_generator | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 답변의 할루시네이션 checker 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 할루시네이션 체크를 위한 데이터 모델 정의\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 호출을 통한 LLM 초기화\n",
    "llm_halluci_checker = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "structured_llm_halluci_checker = llm_halluci_checker.with_structured_output(GradeHallucinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 설정\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n",
    "    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 환각 평가기 생성\n",
    "hallucination_grader = hallucination_prompt | structured_llm_halluci_checker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 답변의 relevant checker 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary scoring to evaluate the appropriateness of answers to questions\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Indicate 'yes' or 'no' whether the answer solves the question\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 호출을 통한 LLM 초기화\n",
    "llm_grader = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "structured_llm_grader = llm_grader.with_structured_output(GradeAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 설정\n",
    "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n \n",
    "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿과 구조화된 LLM 평가기를 결합하여 답변 평가기 생성\n",
    "answer_grader = answer_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 퀴리 재작성 (Query Rewriter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 초기화\n",
    "llm_rewriter = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Rewriter 프롬프트 정의(자유롭게 수정이 가능합니다)\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "\n",
    "# Query Rewriter 프롬프트 템플릿 생성\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Query Rewriter 생성\n",
    "question_rewriter = re_write_prompt | llm_rewriter | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹 검색 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹 검색 도구 생성\n",
    "web_search_tool = TavilySearch(max_results=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphState 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프의 상태 정의\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    그래프의 상태를 나타내는 데이터 모델\n",
    "\n",
    "    Attributes:\n",
    "        question: 질문\n",
    "        generation: LLM 생성된 답변\n",
    "        documents: 도큐먼틑 리스트\n",
    "    \"\"\"\n",
    "\n",
    "    question: Annotated[str, \"User question\"]\n",
    "    generation: Annotated[str, \"LLM generated answer\"]\n",
    "    documents: Annotated[List[str], \"List of documents\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 검색 노드\n",
    "def retrieve(state):\n",
    "    print(\"==== [RETRIEVE] ====\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 문서 검색 수행\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "# 답변 생성 노드\n",
    "def generate(state):\n",
    "    print(\"==== [GENERATE] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG 답변 생성\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "# 문서 관련성 평가 노드\n",
    "def grade_documents(state):\n",
    "    print(\"==== [CHECK DOCUMENT RELEVANCE TO QUESTION] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # 각 문서에 대한 관련성 점수 계산\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            # 관련성이 있는 문서 추가\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            # 관련성이 없는 문서는 건너뛰기\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "\n",
    "# 질문 재작성 노드\n",
    "def transform_query(state):\n",
    "    print(\"==== [TRANSFORM QUERY] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # 질문 재작성\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "# 웹 검색 노드\n",
    "def web_search(state):\n",
    "    print(\"==== [WEB SEARCH] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 웹 검색 수행\n",
    "    web_results = web_search_tool.invoke({\"query\": question})\n",
    "    web_results_docs = [\n",
    "        Document(\n",
    "            page_content=web_result[\"content\"],\n",
    "            metadata={\"source\": web_result[\"url\"]},\n",
    "        )\n",
    "        for web_result in web_results\n",
    "    ]\n",
    "\n",
    "    return {\"documents\": web_results_docs, \"question\": question}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 라우팅 노드\n",
    "def route_question(state):\n",
    "    print(\"==== [ROUTE QUESTION] ====\")\n",
    "    # 질문 가져오기\n",
    "    question = state[\"question\"]\n",
    "    # 질문 라우팅\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    # 질문 라우팅 결과에 따른 노드 라우팅\n",
    "    if source.datasource == \"web_search\":\n",
    "        print(\"==== [ROUTE QUESTION TO WEB SEARCH] ====\")\n",
    "        return \"web_search\"\n",
    "    elif source.datasource == \"vectorstore\":\n",
    "        print(\"==== [ROUTE QUESTION TO VECTORSTORE] ====\")\n",
    "        return \"vectorstore\"\n",
    "\n",
    "\n",
    "# 문서 관련성 평가 노드\n",
    "def decide_to_generate(state):\n",
    "    print(\"==== [DECISION TO GENERATE] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # 모든 문서가 관련성 없는 경우 질문 재작성\n",
    "        print(\n",
    "            \"==== [DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY] ====\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # 관련성 있는 문서가 있는 경우 답변 생성\n",
    "        print(\"==== [DECISION: GENERATE] ====\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def hallucination_check(state):\n",
    "    print(\"==== [CHECK HALLUCINATIONS] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    # 환각 평가\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "\n",
    "    # Hallucination 여부 확인\n",
    "    if grade == \"yes\":\n",
    "        print(\"==== [DECISION: GENERATION IS GROUNDED IN DOCUMENTS] ====\")\n",
    "\n",
    "        # 답변의 관련성(Relevance) 평가\n",
    "        print(\"==== [GRADE GENERATED ANSWER vs QUESTION] ====\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "\n",
    "        # 관련성 평가 결과에 따른 처리\n",
    "        if grade == \"yes\":\n",
    "            print(\"==== [DECISION: GENERATED ANSWER ADDRESSES QUESTION] ====\")\n",
    "            return \"relevant\"\n",
    "        else:\n",
    "            print(\"==== [DECISION: GENERATED ANSWER DOES NOT ADDRESS QUESTION] ====\")\n",
    "            return \"not relevant\"\n",
    "    else:\n",
    "        print(\"==== [DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY] ====\")\n",
    "        return \"hallucination\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import stream_graph, random_uuid, invoke_graph\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# 질문 입력\n",
    "inputs = GraphState(question=\"\"\"Below are instructions for filling out 23 items by referring to the examples. The values shown to the right of the colon (“:”) are examples; please delete them after reviewing and rewrite them with the values found in the PDF. If any item is not mentioned in the PDF, do not remove it—write “None.”\n",
    "1. Electrode (only coin cell)\n",
    "1.1 Cathode active material: NCM-622\n",
    "1.2 Lithium source: LiOH\n",
    "1.3 Nickel supplied during the co-precipitation process of the precursor: NiSO4·6H2O\n",
    "1.4 Cobalt supplied during the co-precipitation process of the precursor: CoSO4·7H2O\n",
    "1.5 Manganese supplied during the co-precipitation process of the precursor: MnSO4·H2O\n",
    "1.6 Co-precipitation solution: NaOH, 4M\n",
    "1.7 Crystallization method (Hydrothermal or Sintering): Hydrothermal\n",
    "1.8 Crystallization temperature: 100°C\n",
    "1.9 Crystallization time: 12 hr\n",
    "1.10 Active material : Conductive additive : Binder ratio: 90 : 5 : 5\n",
    "1.11 Electrolyte: LiPF6 (EC, EMC, DEC mixture in a 1:1:1 volume ratio)\n",
    "1.12 Doping: Zr4+ doping\n",
    "1.13 Coating: ZrO2 coating\n",
    "1.14 Additive: FEC 10% addition\n",
    "1.15 Electrode thickness: 100 µm\n",
    "1.16 only Cathode Electrode diameter: 14π\n",
    "1.17 Loading density: 0.005 g/cm^2\n",
    "1.18 Commercial NCM (check if specified in the paper): No\n",
    "2. Cathode Performance\n",
    "2.1 Capacity at all C-rate, mAh/g (with electrode state; e.g., coated or uncoated) : 214.5 mAh/g\n",
    "2.2 Voltage range: 2.8–4.3 V\n",
    "2.3 Temperature: Room temperature and 55°C\n",
    "3. Cathode Equipment\n",
    "3.1 Explanation of SEM results (indicate figure numbers as well):\n",
    "ex) Fig. 2a, b;the NCM-622 seems to have more or less a spherical morphology with a diameter of 3–5 µm, composed of densely packed primary parti-cles\n",
    "3.2 Explanation of TEM results: None\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mrelevance_check\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==== [RELEVANCE CHECK] ====\n",
      "yes\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mllm_answer\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "1. Electrode (only coin cell)\n",
      "1.1 Cathode active material: NCM622\n",
      "1.2 Lithium source: Li2CO3\n",
      "1.3 Nickel supplied during the co-precipitation process of the precursor: NiC4H6O4·4H2O\n",
      "1.4 Cobalt supplied during the co-precipitation process of the precursor: Co(NO3)2·6H2O\n",
      "1.5 Manganese supplied during the co-precipitation process of the precursor: MnC4H6O4·4H2O\n",
      "1.6 Co-precipitation solution: None\n",
      "1.7 Crystallization method (Hydrothermal or Sintering): Sintering\n",
      "1.8 Crystallization temperature: 600°C, 700°C, 800°C\n",
      "1.9 Crystallization time: 12 hr\n",
      "1.10 Active material : Conductive additive : Binder ratio: None\n",
      "1.11 Electrolyte: 1.2 M LiPF6 in EC-EMC (3:7 volume ratio) with 2 wt% VC\n",
      "1.12 Doping: None\n",
      "1.13 Coating: None\n",
      "1.14 Additive: None\n",
      "1.15 Electrode thickness: None\n",
      "1.16 only Cathode Electrode diameter: None\n",
      "1.17 Loading density: ~3 mg/cm²\n",
      "1.18 Commercial NCM (check if specified in the paper): None\n",
      "\n",
      "2. Cathode Performance\n",
      "2.1 Capacity at all C-rate, mAh/g (with electrode state; e.g., coated or uncoated): Initial discharge capacities of 180.7, 206.8, and 195.3 mAh/g for NCM622-600, NCM622-700, and NCM622-800, respectively\n",
      "2.2 Voltage range: 2.8–4.5 V\n",
      "2.3 Temperature: 25°C\n",
      "\n",
      "3. Cathode Equipment\n",
      "3.1 Explanation of SEM results (indicate figure numbers as well): Fig. 4; SEM images show the morphology of the NCM622 samples, indicating a uniform particle distribution.\n",
      "3.2 Explanation of TEM results: None"
     ]
    }
   ],
   "source": [
    "# 그래프 실행\n",
    "stream_graph(\n",
    "    graph=app, \n",
    "    inputs=inputs, \n",
    "    config=config, \n",
    "    node_names=[\"relevance_check\", \"llm_answer\"]\n",
    ")\n",
    "outputs = app.get_state(config).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voltai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
