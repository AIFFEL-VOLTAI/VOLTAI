{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Google Drive 마운트\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Base Folder 및 PDF 경로 설정\n",
        "base_folder = \"/content/drive/MyDrive/AiffelThon/csy/Langgraph_tutorial\"\n",
        "pdf_folder = \"/content/drive/MyDrive/AiffelThon/Input_data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKnVSGtCdy0F",
        "outputId": "cb63bda2-d299-40cc-da4b-3bb4a713b31f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph langchain langchain_openai pypdf2 sentence-transformers faiss-gpu faiss-cpu langchain-community langchain_teddynote python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CdRt5_hbdyxN",
        "outputId": "13925ff5-9d61-439a-8925-2476a426daa1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.61-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting pypdf2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain_teddynote\n",
            "  Downloading langchain_teddynote-0.3.41-py3-none-any.whl.metadata (707 bytes)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.3.25)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.4 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.9-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.48-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 (from langgraph)\n",
            "  Downloading langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting openai<2.0.0,>=1.58.1 (from langchain_openai)\n",
            "  Downloading openai-1.59.4-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.27.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting kiwipiepy (from langchain_teddynote)\n",
            "  Downloading kiwipiepy-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting rank_bm25 (from langchain_teddynote)\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pinecone-client[grpc] (from langchain_teddynote)\n",
            "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting pinecone-text (from langchain_teddynote)\n",
            "  Downloading pinecone_text-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting olefile (from langchain_teddynote)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting pdf2image (from langchain_teddynote)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting anthropic (from langchain_teddynote)\n",
            "  Downloading anthropic-0.42.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting deepl (from langchain_teddynote)\n",
            "  Downloading deepl-1.20.0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting feedparser (from langchain_teddynote)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting tavily-python (from langchain_teddynote)\n",
            "  Downloading tavily_python-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from langchain_teddynote) (2.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.24.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Collecting sgmllib3k (from feedparser->langchain_teddynote)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting kiwipiepy_model<0.21,>=0.20 (from kiwipiepy->langchain_teddynote)\n",
            "  Downloading kiwipiepy_model-0.20.0.tar.gz (34.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->langchain_teddynote) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->langchain_teddynote) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->langchain_teddynote) (2024.2)\n",
            "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client[grpc]->langchain_teddynote)\n",
            "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client[grpc]->langchain_teddynote)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: googleapis-common-protos>=1.53.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client[grpc]->langchain_teddynote) (1.66.0)\n",
            "Requirement already satisfied: grpcio>=1.44.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client[grpc]->langchain_teddynote) (1.68.1)\n",
            "Collecting lz4>=3.1.3 (from pinecone-client[grpc]->langchain_teddynote)\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: protobuf<5.0,>=4.25 in /usr/local/lib/python3.10/dist-packages (from pinecone-client[grpc]->langchain_teddynote) (4.25.5)\n",
            "Collecting protoc-gen-openapiv2<0.0.2,>=0.0.1 (from pinecone-client[grpc]->langchain_teddynote)\n",
            "  Downloading protoc_gen_openapiv2-0.0.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mmh3<5.0.0,>=4.1.0 (from pinecone-text->langchain_teddynote)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.5 in /usr/local/lib/python3.10/dist-packages (from pinecone-text->langchain_teddynote) (3.9.1)\n",
            "Collecting types-requests<3.0.0,>=2.25.0 (from pinecone-text->langchain_teddynote)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting wget<4.0,>=3.2 (from pinecone-text->langchain_teddynote)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.5->pinecone-text->langchain_teddynote) (8.1.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->langchain_teddynote) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Downloading langgraph-0.2.61-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_teddynote-0.3.41-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.9-py3-none-any.whl (37 kB)\n",
            "Downloading langgraph_sdk-0.1.48-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.59.4-py3-none-any.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.42.0-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepl-1.20.0-py3-none-any.whl (36 kB)\n",
            "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwipiepy-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pinecone_text-0.9.0-py3-none-any.whl (23 kB)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Downloading tavily_python-0.5.0-py3-none-any.whl (14 kB)\n",
            "Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.24.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Downloading protoc_gen_openapiv2-0.0.1-py3-none-any.whl (7.9 kB)\n",
            "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: kiwipiepy_model, wget, sgmllib3k\n",
            "  Building wheel for kiwipiepy_model (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kiwipiepy_model: filename=kiwipiepy_model-0.20.0-py3-none-any.whl size=34818026 sha256=4fa3fd8ada1ce51b5fbf62e65e5795f5329ec2293ad49d8ff760db05e8887239\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/b1/66/2be9840f8ef3627d63d93503d81a5e3b41e9498dcb63b00b13\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=013a96d763e7f08f32829c35f5760ee1e475ac70677bc1f44a2e45b8d7d167fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=457b903de03c47db01dab35a0b64dfbebfb4da0d7305072723e4e6660794f38b\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built kiwipiepy_model wget sgmllib3k\n",
            "Installing collected packages: wget, sgmllib3k, mmh3, kiwipiepy_model, faiss-gpu, types-requests, rank_bm25, python-dotenv, pypdf2, pinecone-plugin-interface, pdf2image, olefile, mypy-extensions, marshmallow, lz4, kiwipiepy, httpx-sse, feedparser, faiss-cpu, typing-inspect, tiktoken, protoc-gen-openapiv2, pinecone-text, pinecone-plugin-inference, deepl, tavily-python, pydantic-settings, pinecone-client, openai, langgraph-sdk, dataclasses-json, anthropic, langchain-core, langgraph-checkpoint, langchain_openai, langgraph, langchain, langchain_teddynote, langchain-community\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.57.4\n",
            "    Uninstalling openai-1.57.4:\n",
            "      Successfully uninstalled openai-1.57.4\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.25\n",
            "    Uninstalling langchain-core-0.3.25:\n",
            "      Successfully uninstalled langchain-core-0.3.25\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.12\n",
            "    Uninstalling langchain-0.3.12:\n",
            "      Successfully uninstalled langchain-0.3.12\n",
            "Successfully installed anthropic-0.42.0 dataclasses-json-0.6.7 deepl-1.20.0 faiss-cpu-1.9.0.post1 faiss-gpu-1.7.2 feedparser-6.0.11 httpx-sse-0.4.0 kiwipiepy-0.20.3 kiwipiepy_model-0.20.0 langchain-0.3.14 langchain-community-0.3.14 langchain-core-0.3.29 langchain_openai-0.2.14 langchain_teddynote-0.3.41 langgraph-0.2.61 langgraph-checkpoint-2.0.9 langgraph-sdk-0.1.48 lz4-4.3.3 marshmallow-3.24.1 mmh3-4.1.0 mypy-extensions-1.0.0 olefile-0.47 openai-1.59.4 pdf2image-1.17.0 pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7 pinecone-text-0.9.0 protoc-gen-openapiv2-0.0.1 pydantic-settings-2.7.1 pypdf2-3.0.1 python-dotenv-1.0.1 rank_bm25-0.2.2 sgmllib3k-1.0.0 tavily-python-0.5.0 tiktoken-0.8.0 types-requests-2.32.0.20241016 typing-inspect-0.9.0 wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqC6dChmkl_O",
        "outputId": "c5ed4caa-9bcd-4318-884e-1a152290b0dc",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jlFcOgnmdhSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c65479-3089-4450-a797-dedfae024b27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "## retriever\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.vectorstores.base import VectorStoreRetriever\n",
        "\n",
        "## tool\n",
        "from langgraph.prebuilt import ToolExecutor\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "\n",
        "## agent\n",
        "import operator\n",
        "from typing import Annotated, Sequence, TypedDict\n",
        "\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "## Nodes and Edges\n",
        "import json\n",
        "import operator\n",
        "from typing import Annotated, Sequence, TypedDict\n",
        "\n",
        "from langchain import hub\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
        "from langchain_core.messages import BaseMessage, FunctionMessage, HumanMessage\n",
        "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.prebuilt import ToolInvocation\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "## Graph\n",
        "from langgraph.graph import END, StateGraph\n",
        "\n",
        "## Response\n",
        "import pprint\n",
        "from langchain_core.messages import HumanMessage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "dotenv_path = os.path.join(base_folder, \".env\")\n",
        "\n",
        "# .env 파일 로드\n",
        "load_dotenv(dotenv_path=dotenv_path)\n",
        "\n",
        "# API 키 가져오기\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "\n",
        "# LangSmith 추적 기능을 활성화합니다. (선택적)\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"Multi-agent Collaboration\""
      ],
      "metadata": {
        "id": "lfdkoLTZdrVU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PDF 파일을 경로로 불러들임"
      ],
      "metadata": {
        "id": "tN2VrtkHlw6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_pdfs = []  # PDF 경로를 저장할 리스트\n",
        "\n",
        "for i in range(1, 144):\n",
        "    input_pdf = os.path.join(pdf_folder, f\"paper_{str(i).zfill(3)}.pdf\")\n",
        "    input_pdfs.append(input_pdf)\n",
        "\n",
        "# 출력 (테스트용)\n",
        "for pdf in input_pdfs:\n",
        "    print(pdf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sg3YnMPNepId",
        "outputId": "e483097c-762b-42b4-fa8f-4634d255577e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_001.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_002.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_003.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_004.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_005.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_006.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_007.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_008.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_009.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_010.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_011.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_012.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_013.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_014.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_015.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_016.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_017.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_018.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_019.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_020.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_021.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_022.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_023.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_024.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_025.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_026.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_027.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_028.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_029.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_030.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_031.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_032.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_033.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_034.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_035.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_036.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_037.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_038.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_039.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_040.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_041.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_042.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_043.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_044.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_045.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_046.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_047.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_048.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_049.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_050.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_051.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_052.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_053.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_054.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_055.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_056.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_057.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_058.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_059.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_060.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_061.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_062.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_063.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_064.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_065.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_066.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_067.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_068.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_069.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_070.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_071.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_072.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_073.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_074.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_075.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_076.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_077.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_078.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_079.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_080.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_081.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_082.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_083.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_084.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_085.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_086.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_087.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_088.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_089.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_090.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_091.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_092.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_093.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_094.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_095.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_096.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_097.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_098.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_099.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_100.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_101.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_102.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_103.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_104.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_105.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_106.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_107.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_108.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_109.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_110.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_111.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_112.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_113.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_114.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_115.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_116.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_117.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_118.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_119.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_120.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_121.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_122.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_123.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_124.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_125.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_126.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_127.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_128.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_129.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_130.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_131.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_132.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_133.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_134.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_135.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_136.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_137.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_138.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_139.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_140.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_141.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_142.pdf\n",
            "/content/drive/MyDrive/AiffelThon/Input_data/paper_143.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def embedding_file(file: str) -> VectorStoreRetriever:\n",
        "    \"\"\"문서를 청크 단위로 분할하고 임베딩 모델(text-embedding-ada-002)을 통해 임베딩하여 vector store에 저장합니다. 이후 vector store를 기반으로 검색하는 객체를 생성합니다.\n",
        "\n",
        "    Args:\n",
        "        file (str): pdf 문서 경로\n",
        "\n",
        "    Returns:\n",
        "        VectorStoreRetriever: 검색기\n",
        "    \"\"\"\n",
        "\n",
        "    ## 긴 텍스트를 작은 청크로 나누는 데 사용되는 클래스\n",
        "    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "        chunk_size=500,         ## 최대 청크 길이 정의\n",
        "        chunk_overlap=100,      ## 청크 간 겹침 길이 정의\n",
        "        separators=[\"\\n\\n\"]     ## 텍스트를 나눌 때 사용할 구분자를 지정 (문단)\n",
        "    )\n",
        "\n",
        "    ## PDF 파일 불러오기\n",
        "    loader = PyPDFLoader(f\"{file}\")\n",
        "    docs = loader.load_and_split(text_splitter=splitter)\n",
        "\n",
        "    ## Embedding 생성 및 vector store에 저장\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vector_store = FAISS.from_documents(\n",
        "        documents=docs,         ## 벡터 저장소에 추가할 문서 리스트\n",
        "        embedding=embeddings    ## 사용할 임베딩 함수\n",
        "    )\n",
        "\n",
        "    ## 검색기로 변환: 현재 벡터 저장소를 기반으로 VectorStoreRetriever 객체를 생성하는 기능을 제공\n",
        "    retriever = vector_store.as_retriever(\n",
        "        search_type=\"similarity\"    ## 어떻게 검색할 것인지? default가 유사도\n",
        "    )\n",
        "\n",
        "    return retriever"
      ],
      "metadata": {
        "id": "V8-u7FyEjw4U"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 아래의 input_pdfs[i]를 조절해서 input을 대량으로 끌고오는 걸 고려해봐야함"
      ],
      "metadata": {
        "id": "N51CGgNml2hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = embedding_file(file=input_pdfs[138])"
      ],
      "metadata": {
        "id": "59zS_Yp_kXFY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated, TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "# GraphState 상태 정의\n",
        "class GraphState(TypedDict):\n",
        "    question: Annotated[str, \"Question\"]  # 질문\n",
        "    context: Annotated[str, \"Context\"]  # 문서의 검색 결과\n",
        "    answer: Annotated[str, \"Answer\"]  # 답변\n",
        "    messages: Annotated[list, add_messages]  # 메시지(누적되는 list)"
      ],
      "metadata": {
        "id": "Ir0MiD_vqImN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_teddynote.messages import messages_to_history\n",
        "from langchain_core.documents.base import Document\n",
        "from langchain_teddynote.evaluator import GroundednessChecker\n",
        "\n",
        "def format_docs(docs: list[Document]) -> str:\n",
        "    \"\"\"문시 리스트에서 텍스트를 추출하여 하나의 문자로 합치는 기능을 합니다.\n",
        "\n",
        "    Args:\n",
        "        docs (list[Document]): 여러 개의 Documnet 객체로 이루어진 리스트\n",
        "\n",
        "    Returns:\n",
        "        str: 모든 문서의 텍스트가 하나로 합쳐진 문자열을 반환\n",
        "    \"\"\"\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# 문서 검색 노드\n",
        "def retrieve_document(state: GraphState) -> GraphState:\n",
        "    # 질문을 상태에서 가져옵니다.\n",
        "    latest_question = state[\"question\"]\n",
        "\n",
        "    # 문서에서 검색하여 관련성 있는 문서를 찾습니다.\n",
        "    retrieved_docs = retriever.invoke(latest_question)\n",
        "\n",
        "    # 검색된 문서를 형식화합니다.(프롬프트 입력으로 넣어주기 위함)\n",
        "    retrieved_docs = format_docs(retrieved_docs)\n",
        "\n",
        "    # 검색된 문서를 context 키에 저장합니다.\n",
        "    return GraphState(context=retrieved_docs)\n",
        "\n",
        "\n",
        "# 답변 생성 노드\n",
        "def llm_answer(state: GraphState) -> GraphState:\n",
        "    # 질문을 상태에서 가져옵니다.\n",
        "    latest_question = state[\"question\"]\n",
        "\n",
        "    # 검색된 문서를 상태에서 가져옵니다.\n",
        "    context = state[\"context\"]\n",
        "\n",
        "    # prompt 설정\n",
        "    prompt = PromptTemplate(\n",
        "        template=\"\"\"\n",
        "        Based on the following document, please provide an answer to the given question.\n",
        "\n",
        "        Document:\n",
        "        {context}\n",
        "\n",
        "        Question:\n",
        "        {question}\n",
        "\n",
        "        Answer:\n",
        "        \"\"\",\n",
        "        input_variables=[\"context\", \"question\"],\n",
        "        )\n",
        "\n",
        "    # llm 호출\n",
        "    llm = ChatOpenAI(\n",
        "        model_name=\"gpt-4o\",\n",
        "        temperature=0.7,\n",
        "        streaming=True\n",
        "        )\n",
        "\n",
        "    # 체인 호출\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "    response = chain.invoke(\n",
        "        {\n",
        "            \"question\": latest_question,\n",
        "            \"context\": context,\n",
        "            \"chat_history\": messages_to_history(state[\"messages\"]),\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # 생성된 답변, (유저의 질문, 답변) 메시지를 상태에 저장합니다.\n",
        "    return GraphState(\n",
        "        answer=response,\n",
        "        messages=[(\"user\", latest_question), (\"assistant\", response)]\n",
        "    )\n",
        "\n",
        "\n",
        "# 관련성 체크 노드\n",
        "def relevance_check(state: GraphState) -> GraphState:\n",
        "    # 관련성 평가기를 생성합니다.\n",
        "    retrieval_answer_relevant = GroundednessChecker(\n",
        "        llm=ChatOpenAI(model=\"gpt-4o\", temperature=0.7), target=\"retrieval-answer\"\n",
        "    ).create()\n",
        "\n",
        "    # 관련성 체크를 실행(\"yes\" or \"no\")\n",
        "    response = retrieval_answer_relevant.invoke(\n",
        "        {\"context\": state[\"context\"], \"answer\": state[\"answer\"]}\n",
        "    )\n",
        "\n",
        "    print(\"==== [RELEVANCE CHECK] ====\")\n",
        "    print(response.score)\n",
        "\n",
        "    # 참고: 여기서의 관련성 평가기는 각자의 Prompt 를 사용하여 수정할 수 있습니다. 여러분들의 Groundedness Check 를 만들어 사용해 보세요!\n",
        "    return GraphState(relevance=response.score)\n",
        "\n",
        "\n",
        "# 관련성 체크하는 함수(router)\n",
        "def is_relevant(state: GraphState) -> GraphState:\n",
        "    return state[\"relevance\"]"
      ],
      "metadata": {
        "id": "WwbDrtLZfAis"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langgraph.graph import END, StateGraph\n",
        "# from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# # 그래프 생성\n",
        "# workflow = StateGraph(GraphState)\n",
        "\n",
        "# # 노드 정의\n",
        "# workflow.add_node(\"retrieve\", retrieve_document)\n",
        "# workflow.add_node(\"relevance_check\", relevance_check)\n",
        "# workflow.add_node(\"llm_answer\", llm_answer)\n",
        "\n",
        "# # 엣지 정의\n",
        "# workflow.add_edge(\"retrieve\", \"relevance_check\")  # 검색 -> 관련성 체크\n",
        "\n",
        "# # 조건부 엣지를 추가합니다.\n",
        "# workflow.add_conditional_edges(\n",
        "#     \"relevance_check\",  # 관련성 체크 노드에서 나온 결과를 is_relevant 함수에 전달합니다.\n",
        "#     is_relevant,\n",
        "#     {\n",
        "#         \"yes\": \"llm_answer\",  # 관련성이 있으면 답변을 생성합니다.\n",
        "#         \"no\": \"retrieve\",  # 관련성이 없으면 다시 검색합니다.\n",
        "#     },\n",
        "# )\n",
        "\n",
        "# # 그래프 진입점 설정\n",
        "# workflow.set_entry_point(\"retrieve\")\n",
        "\n",
        "# # 체크포인터 설정\n",
        "# memory = MemorySaver()\n",
        "\n",
        "# # 컴파일\n",
        "# app = workflow.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "Aq1VMf2SfObk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import START, END, StateGraph\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# 그래프 생성\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# 노드 정의\n",
        "workflow.add_node(\"retrieve\", retrieve_document)\n",
        "workflow.add_node(\"relevance_check\", relevance_check)\n",
        "workflow.add_node(\"llm_answer\", llm_answer)\n",
        "\n",
        "# 엣지 정의\n",
        "workflow.add_edge(\"retrieve\", \"llm_answer\")  # _start_ -> 검색 시작\n",
        "workflow.add_edge(\"llm_answer\", \"relevance_check\")  # 답변 생성 -> 관련성 체크\n",
        "\n",
        "# 조건부 엣지를 추가합니다.\n",
        "workflow.add_conditional_edges(\n",
        "    \"relevance_check\",  # 관련성 체크 노드에서 나온 결과를 is_relevant 함수에 전달합니다.\n",
        "    is_relevant,\n",
        "    {\n",
        "        \"yes\": END,  # 관련성이 있으면 _end_로 이동합니다.\n",
        "        \"no\": \"retrieve\",  # 관련성이 없으면 다시 검색합니다.\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "# 그래프 진입점 설정\n",
        "workflow.set_entry_point(\"retrieve\")\n",
        "\n",
        "# 체크포인터 설정\n",
        "memory = MemorySaver()\n",
        "\n",
        "# 컴파일\n",
        "app = workflow.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "vskGrICPw6wO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_teddynote.graphs import visualize_graph\n",
        "\n",
        "visualize_graph(app)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "JskQ7y8PfUVK",
        "outputId": "e77ffef0-2923-4e77-e36d-0f87837c2982"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_core.runnables import RunnableConfig\n",
        "# from langchain_teddynote.messages import stream_graph, random_uuid, invoke_graph\n",
        "\n",
        "# # config 설정(재귀 최대 횟수, thread_id)\n",
        "# config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
        "\n",
        "# # 질문 입력\n",
        "# inputs = GraphState(question=\"\"\"Below are instructions for filling out items by referring to the examples.\n",
        "# The values shown to the right of the colon (“:”) are examples;\n",
        "# please delete them after reviewing and rewrite them with the values found in the PDF.\n",
        "# If any item is not mentioned in the PDF, do not remove it—write “None.”\n",
        "\n",
        "# 2.1 Cathode Active material, Conductive additive, Binder ratio: 90, 5, 5\n",
        "# 2.2 Electrolyte: LiPF6 (EC, EMC, DEC mixture in a 1:1:1 volume ratio)\n",
        "# 2.3 Additive: FEC 10% addition\n",
        "# 2.4 Electrode thickness: 100 µm\n",
        "# 2.5 only Cathode Electrode diameter: 14π\n",
        "# 2.6 Cathode Electrode area: 1.5 cm^2\n",
        "# 2.7 Loading density (mass loading of NCM): 0.005 g/cm^2\n",
        "# 2.8 additional treatment for electrode: None\"\"\")"
      ],
      "metadata": {
        "id": "fRLgsCG-fV2E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 그래프 실행\n",
        "# stream_graph(\n",
        "#     graph=app,\n",
        "#     inputs=inputs,\n",
        "#     config=config,\n",
        "#     node_names=[\"relevance_check\", \"llm_answer\"]\n",
        "# )\n",
        "# outputs = app.get_state(config).values"
      ],
      "metadata": {
        "id": "O4_CRkG3nV6Z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import json\n",
        "\n",
        "# # 'outputs'에서 'answer' 값 추출\n",
        "# answer_value = outputs['answer']\n",
        "\n",
        "# # 저장할 폴더와 파일 이름 지정\n",
        "# save_folder = \"/content/drive/MyDrive/AiffelThon/csy/Langgraph_tutorial/json\"  # 원하는 경로로 변경\n",
        "# file_name = \"answer_value_2.json\"\n",
        "\n",
        "# # 경로를 합쳐 JSON 파일 전체 경로 생성\n",
        "# save_path = os.path.join(save_folder, file_name)\n",
        "\n",
        "# # JSON 파일로 저장\n",
        "# with open(save_path, 'w', encoding='utf-8') as json_file:\n",
        "#     json.dump({\"answer\": answer_value}, json_file, ensure_ascii=False, indent=4)\n",
        "\n",
        "# print(f\"answer_value가 JSON 파일로 저장되었습니다: {save_path}\")\n"
      ],
      "metadata": {
        "id": "lBMhMP2tuEa9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableConfig\n",
        "from langchain_teddynote.messages import stream_graph, random_uuid, invoke_graph\n",
        "\n",
        "# config 설정(재귀 최대 횟수, thread_id)\n",
        "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
        "\n",
        "# 4개의 질문 입력\n",
        "questions = [\n",
        "    \"\"\"Below are instructions for filling out items by referring to the examples.\n",
        "    The values shown to the right of the colon (“:”) are examples;\n",
        "    please delete them after reviewing and rewrite them with the values found in the PDF.\n",
        "    If any item is not mentioned in the PDF, do not remove it—write “None.”\n",
        "\n",
        "    1. CAM (Cathode Active Material)\n",
        "    1.1 Stoichiometry information: NCM-622\n",
        "    1.2 Commercial NCM (check if specified in the paper): No\n",
        "    1.3 Lithium source: LiOH\n",
        "    1.4 Synthesis method (co-precipitation or Sol-gel method): co-precipitation\n",
        "    1.5 Crystallization method (Hydrothermal or Sintering): Hydrothermal\n",
        "    1.6 Crystallization temperature: 100°C\n",
        "    1.7 Crystallization time: 12 hr\n",
        "    1.8 Doping: Zr4+ doping\n",
        "    1.9 Coating: ZrO2 coating\n",
        "    1.10 additional treatment: None\"\"\",\n",
        "\n",
        "    \"\"\"Below are instructions for filling out items by referring to the examples.\n",
        "    The values shown to the right of the colon (“:”) are examples;\n",
        "    please delete them after reviewing and rewrite them with the values found in the PDF.\n",
        "    If any item is not mentioned in the PDF, do not remove it—write “None.”\n",
        "\n",
        "    2.1 Active material, Conductive additive, Binder ratio: 90, 5, 5\n",
        "    2.2 Electrolyte: LiPF6 (EC, EMC, DEC mixture in a 1:1:1 volume ratio)\n",
        "    2.3 Additive: FEC 10% addition\n",
        "    2.4 Electrode thickness: 100 µm\n",
        "    2.5 only Cathode Electrode diameter: 14π\n",
        "    2.6 Cathode Electrode area: 1.5 cm^2\n",
        "    2.7 Loading ammount (mass loading of CAM): 25 mg\n",
        "    2.8 Loading density: 9.1 mg/cm^2\"\"\",\n",
        "\n",
        "    \"\"\"Below are instructions for filling out items by referring to the examples.\n",
        "    The values shown to the right of the colon (“:”) are examples;\n",
        "    please delete them after reviewing and rewrite them with the values found in the PDF.\n",
        "    If any item is not mentioned in the PDF, do not remove it—write “None.”\n",
        "\n",
        "    3. Morphological results\n",
        "    3.1 Explanation of SEM results (indicate figure numbers as well):\n",
        "    ex) Fig. 2a, b;the NCM-622 seems to have a spherical morphology with a diameter of 3–5 µm, composed of densely packed primary particles\n",
        "    3.2 Explanation of TEM results: None\"\"\",\n",
        "\n",
        "    \"\"\"Below are instructions for filling out items by referring to the examples.\n",
        "    The values shown to the right of the colon (“:”) are examples;\n",
        "    please delete them after reviewing and rewrite them with the values found in the PDF.\n",
        "    If any item is not mentioned in the PDF, do not remove it—write “None.”\n",
        "\n",
        "    4. Cathode Performance\n",
        "    4.1 Capacity at all C-rate, mAh/g (with electrode state; e.g., coated or uncoated): {\"214.5 mAh/g\":\"@0.1C, ZrO2-coated\", \"200.8 mAh/g\":\"@0.5C, ZrO2-coated\"}\n",
        "    4.2 Voltage range: 2.8–4.3 V\n",
        "    4.3 Temperature: Room temperature and 55°C\"\"\"\n",
        "]\n",
        "\n",
        "# 4개의 질문에 대해 그래프 실행 및 출력\n",
        "outputs = []\n",
        "for i, question in enumerate(questions):\n",
        "    inputs = GraphState(question=question)\n",
        "    stream_graph(\n",
        "        graph=app,\n",
        "        inputs=inputs,\n",
        "        config=config,\n",
        "        node_names=[\"relevance_check\", \"llm_answer\"]\n",
        "    )\n",
        "    output = app.get_state(config).values\n",
        "    outputs.append(output)"
      ],
      "metadata": {
        "id": "xOIXfqnWwWDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23f95314-515f-49ba-9dc5-8ecc9f07564a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mllm_answer\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "1. CAM (Cathode Active Material)\n",
            "1.1 Stoichiometry information: Li[Ni0.73Co0.12Mn0.15]O2\n",
            "1.2 Commercial NCM (check if specified in the paper): No\n",
            "1.3 Lithium source: LiOH\n",
            "1.4 Synthesis method (co-precipitation or Sol-gel method): co-precipitation\n",
            "1.5 Crystallization method (Hydrothermal or Sintering): Sintering\n",
            "1.6 Crystallization temperature: 750°C\n",
            "1.7 Crystallization time: 20 hr\n",
            "1.8 Doping: None\n",
            "1.9 Coating: Al2O3 coating\n",
            "1.10 additional treatment: None\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mrelevance_check\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==== [RELEVANCE CHECK] ====\n",
            "yes\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mllm_answer\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "2.1 Active material, Conductive additive, Binder ratio: 80, 10, 10  \n",
            "2.2 Electrolyte: LiPF6 (EC, DEC, DMC mixture in a 1:1:1 volume ratio)  \n",
            "2.3 Additive: None  \n",
            "2.4 Electrode thickness: None  \n",
            "2.5 only Cathode Electrode diameter: None  \n",
            "2.6 Cathode Electrode area: 1.5 cm^2  \n",
            "2.7 Loading amount (mass loading of CAM): 2.5 mg  \n",
            "2.8 Loading density: None  \n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mrelevance_check\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==== [RELEVANCE CHECK] ====\n",
            "yes\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mllm_answer\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "3. Morphological results  \n",
            "3.1 Explanation of SEM results (indicate figure numbers as well):  \n",
            "Fig. 2a, b, c; The pristine Li[Ni0.73Co0.12Mn0.15]O2 material has a well-dispersed spherical shape with an average particle size of approximately 12 µm, composed of numerous primary grains of 100-200 nm that are aggregated. After Al2O3 surface modification, the morphology of the FD-Al2O3-coated and HD-Al2O3-coated samples is similar to the pristine sample, indicating a thin Al2O3 layer and mild modification processes.\n",
            "\n",
            "3.2 Explanation of TEM results:  \n",
            "The TEM analysis shows that the pristine material has a very smooth edge line without any layer on the surface. For the FD-Al2O3-coated material, there seems to be a uniform and indistinct coating layer covered on the surface with a thickness of about 5 nm, while the HD-Al2O3-coated material shows some Al2O3 nanoparticles aggregated non-uniformly on the surface.\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mrelevance_check\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==== [RELEVANCE CHECK] ====\n",
            "yes\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mllm_answer\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "4. Cathode Performance  \n",
            "4.1 Capacity at all C-rate, mAh/g (with electrode state; e.g., coated or uncoated): {\"214 mAh/g\":\"@0.1C, FD-Al2O3-coated\", \"226 mAh/g\":\"@0.1C, pristine\", \"192 mAh/g\":\"@0.1C, HD-Al2O3-coated\"}  \n",
            "4.2 Voltage range: 3.0–4.3 V  \n",
            "4.3 Temperature: Room temperature and 55°C  \n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mrelevance_check\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==== [RELEVANCE CHECK] ====\n",
            "yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O9Rf5gKLqSaD"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}