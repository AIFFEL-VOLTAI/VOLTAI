{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from retriever.retriever_handler import get_retriever\n",
    "from utils.utils import format_docs\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env 파일 로드\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "# API 키 가져오기\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# LangSmith 추적 기능을 활성화합니다. (선택적)\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SampleNameSearcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = get_retriever(\n",
    "            file_folder=\"./data/raw\", \n",
    "            file_number=11,\n",
    "            chunk_size=500, \n",
    "            chunk_overlap=100, \n",
    "            search_k=10\n",
    "        )\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.1)\n",
    "\n",
    "sample_name_retriever_prompt = \"\"\"\n",
    "You are an expert assistant specializing in extracting information from research papers related to battery technology. Your role is to carefully analyze the provided document.\n",
    "\n",
    "Document:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", sample_name_retriever_prompt), \n",
    "    (\"human\", \"{sample_name_question}\")\n",
    "])\n",
    "\n",
    "sample_name_searcher_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs, \n",
    "        \"sample_name_question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt \n",
    "    | model \n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name_question = \"\"\"\n",
    "Use all of the NCM cathode sample names (e.g., 'NCM-622', 'pristine NCM', 'M-NCM') provided in the electrochemical performance section. You just output sample names. Do Not output like '- NCM622' , just output 'NCM622.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = sample_name_searcher_chain.invoke(sample_name_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NR0', 'NR1', 'NR3', 'NR5']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_c1 = f\"\"\"\n",
    "Extract the following information for {sample_names}:\n",
    "    - The exact chemical composition (stoichiometry) of the cathode active material (CAM) used in the study.\n",
    "    - The type of commercially used NCM (e.g., LiNixCoyMnzO2), including code names or abbreviations (e.g., NCM811, N-NCM, SC-NCM) if applicable.\n",
    "    - The lithium source used for synthesizing the NCM.\n",
    "    - The synthesis method used for preparing the NCM samples (e.g., co-precipitation, sol-gel), including intermediate steps if reported.\n",
    "    - The crystallization method used (e.g., solid-state sintering, hydrothermal), and the specific final temperatures and durations used in the process.\n",
    "    - Whether any doping technique was applied to the CAM, and if so, which element(s) were doped.\n",
    "    - Whether any coating layer was applied to the CAM, and if so, what material was used for coating.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_c2 = f\"\"\"\n",
    "Extract the following information for {sample_names}:\n",
    "    - The electrode composition, including the mass ratios of active material, conductive additive (e.g., Super P), and binder (e.g., PVDF).\n",
    "    - The type of electrolyte solvent used (e.g., EC/DEC, EC/EMC/DEC), including volume or mass ratios if available.\n",
    "    - The lithium salt used in the electrolyte (e.g., LiPF6), and its concentration (e.g., 1 M or 1 mol/L).\n",
    "    - Any additives used in the electrolyte, including their names and concentrations if reported.\n",
    "    - The mass loading (in mg/cm²) of the NCM active material used in the electrode.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_c3 = f\"\"\"\n",
    "Extract the following information for {sample_names}:\n",
    "    - Particle size information from SEM or TEM images, including both secondary and primary particles if available.\n",
    "    - Descriptions of the particle shape observed in SEM or TEM data.\n",
    "    - Observations on particle distribution or uniformity reported in the SEM or TEM analysis.\n",
    "    - If a coating was applied, the reported properties and thickness of the coating layer as observed in SEM or TEM.\n",
    "    - The crystal structure and lattice characteristics (e.g., crystal plane spacing, presence of layered structure) from structural analysis.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_c4 = f\"\"\"\n",
    "Extract the following information for {sample_names}:\n",
    "    - The voltage range and temperature used in electrochemical tests\n",
    "    - The specific discharge capacities reported at various C-rates:\n",
    "        - 0.1C\n",
    "        - 0.2C\n",
    "        - 0.5C\n",
    "        - 1.0C\n",
    "        - 2.0C\n",
    "        - Any additional C-rate values and performance data reported\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_questions = [question_c1, question_c2, question_c3, question_c4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\nExtract the following information for ['NR0', 'NR1', 'NR3', 'NR5']:\\n    - The exact chemical composition (stoichiometry) of the cathode active material (CAM) used in the study.\\n    - The type of commercially used NCM (e.g., LiNixCoyMnzO2), including code names or abbreviations (e.g., NCM811, N-NCM, SC-NCM) if applicable.\\n    - The lithium source used for synthesizing the NCM.\\n    - The synthesis method used for preparing the NCM samples (e.g., co-precipitation, sol-gel), including intermediate steps if reported.\\n    - The crystallization method used (e.g., solid-state sintering, hydrothermal), and the specific final temperatures and durations used in the process.\\n    - Whether any doping technique was applied to the CAM, and if so, which element(s) were doped.\\n    - Whether any coating layer was applied to the CAM, and if so, what material was used for coating.\\n\",\n",
       " \"\\nExtract the following information for ['NR0', 'NR1', 'NR3', 'NR5']:\\n    - The electrode composition, including the mass ratios of active material, conductive additive (e.g., Super P), and binder (e.g., PVDF).\\n    - The type of electrolyte solvent used (e.g., EC/DEC, EC/EMC/DEC), including volume or mass ratios if available.\\n    - The lithium salt used in the electrolyte (e.g., LiPF6), and its concentration (e.g., 1 M or 1 mol/L).\\n    - Any additives used in the electrolyte, including their names and concentrations if reported.\\n    - The mass loading (in mg/cm²) of the NCM active material used in the electrode.\\n\",\n",
       " \"\\nExtract the following information for ['NR0', 'NR1', 'NR3', 'NR5']:\\n    - Particle size information from SEM or TEM images, including both secondary and primary particles if available.\\n    - Descriptions of the particle shape observed in SEM or TEM data.\\n    - Observations on particle distribution or uniformity reported in the SEM or TEM analysis.\\n    - If a coating was applied, the reported properties and thickness of the coating layer as observed in SEM or TEM.\\n    - The crystal structure and lattice characteristics (e.g., crystal plane spacing, presence of layered structure) from structural analysis.\\n\",\n",
       " \"\\nExtract the following information for ['NR0', 'NR1', 'NR3', 'NR5']:\\n    - The voltage range and temperature used in electrochemical tests\\n    - The specific discharge capacities reported at various C-rates:\\n        - 0.1C\\n        - 0.2C\\n        - 0.5C\\n        - 1.0C\\n        - 2.0C\\n        - Any additional C-rate values and performance data reported\\n\"]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retriever.retriever_handler import get_retriever\n",
    "from langchain.tools import Tool\n",
    "from langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation\n",
    "import json\n",
    "from langchain_core.messages import FunctionMessage\n",
    "\n",
    "## retriever 설정\n",
    "retriever = get_retriever(\n",
    "    file_folder=\"./data/raw\", \n",
    "    file_number=11,\n",
    "    chunk_size=500, \n",
    "    chunk_overlap=100, \n",
    "    search_k=10\n",
    ")\n",
    "retriever_tool = Tool(\n",
    "    name=\"retriever\",\n",
    "    func=retriever.get_relevant_documents,\n",
    "    description=\"Retrieve relevant documents based on a query.\"\n",
    ")     \n",
    "\n",
    "## set tool\n",
    "tools = [retriever_tool]\n",
    "tool_executor = ToolExecutor(tools)\n",
    "\n",
    "def tool_node(state):\n",
    "    # 그래프에서 도구를 실행하는 함수입니다.\n",
    "    # 에이전트 액션을 입력받아 해당 도구를 호출하고 결과를 반환합니다.\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # 계속 조건에 따라 마지막 메시지가 함수 호출을 포함하고 있음을 알 수 있습니다.\n",
    "    first_message = messages[0]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # ToolInvocation을 함수 호출로부터 구성합니다.\n",
    "    tool_input = json.loads(last_message.additional_kwargs[\"function_call\"][\"arguments\"])\n",
    "    tool_name = last_message.additional_kwargs[\"function_call\"][\"name\"]\n",
    "    \n",
    "    if tool_name == \"retriever\":\n",
    "        base_query = tool_input.get(\"__arg1\", \"\")  # 기존 query 가져오기\n",
    "        refined_query = f\"Context: {first_message.content} | Query: {base_query}\"\n",
    "        tool_input[\"__arg1\"] = refined_query\n",
    "    \n",
    "    # 단일 인자 입력은 값으로 직접 전달할 수 있습니다.\n",
    "    if len(tool_input) == 1 and \"__arg1\" in tool_input:\n",
    "        tool_input = next(iter(tool_input.values()))\n",
    "    \n",
    "    action = ToolInvocation(\n",
    "        tool=tool_name,\n",
    "        tool_input=tool_input,\n",
    "    )\n",
    "    \n",
    "    # 도구 실행자를 호출하고 응답을 받습니다.\n",
    "    response = tool_executor.invoke(action)\n",
    "    \n",
    "    # 응답을 사용하여 FunctionMessage를 생성합니다.\n",
    "    function_message = FunctionMessage(\n",
    "        content=f\"{tool_name} response: {str(response)}\", name=action.tool\n",
    "    )\n",
    "    \n",
    "    # 기존 리스트에 추가될 리스트를 반환합니다.\n",
    "    return {\"messages\": [function_message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"), \n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools) \n",
    "    \n",
    "    return executor\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "members = [\"Researcher1\", \"Researcher2\", \"Researcher3\", \"Researcher4\"]\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"next\": {\n",
    "                \"title\": \"Next\",\n",
    "                \"anyOf\": [\n",
    "                    {\"enum\": options},\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "supervisor_chain = (\n",
    "    prompt\n",
    "    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "    | JsonOutputFunctionsParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import functools\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "researcher_system_prompt = \"\"\"You are a Researcher Agent, responsible for extracting structured and detailed information from scientific papers, specifically in the field of lithium-ion battery materials. Your task is to answer a specific sub-question assigned by the Supervisor by retrieving information from the given paper.\n",
    "  ## Your Responsibilities:\n",
    "    1. Extract information strictly from the paper without making assumptions or hallucinations.\n",
    "    2. Write the response as a single, coherent technical paragraph (not bullet points or lists).\n",
    "    3. Use precise scientific language, such as:\n",
    "        - \"was synthesized by...\"\n",
    "        - \"was reported to exhibit...\"\n",
    "        - \"was not mentioned in the paper...\"\n",
    "    4. If a detail is not reported in the paper, explicitly state it (e.g., “The composition data was not mentioned.”).\n",
    "    5. Maintain logical flow and consistency in your paragraph.\n",
    "\n",
    "  If your response contains incorrect, missing, or unclear information, you must revise and resubmit it.\"\"\"\n",
    "\n",
    "researcher1_agent = create_agent(llm, tools, researcher_system_prompt)\n",
    "researcher1_node = functools.partial(agent_node, agent=researcher1_agent, name=\"Researcher1\")\n",
    "researcher2_agent = create_agent(llm, tools, researcher_system_prompt)\n",
    "researcher2_node = functools.partial(agent_node, agent=researcher2_agent, name=\"Researcher2\")\n",
    "researcher3_agent = create_agent(llm, tools, researcher_system_prompt)\n",
    "researcher3_node = functools.partial(agent_node, agent=researcher3_agent, name=\"Researcher3\")\n",
    "researcher4_agent = create_agent(llm, tools, researcher_system_prompt)\n",
    "researcher4_node = functools.partial(agent_node, agent=researcher4_agent, name=\"Researcher4\")\n",
    "\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Researcher1\", researcher1_node)\n",
    "workflow.add_node(\"Researcher2\", researcher2_node)\n",
    "workflow.add_node(\"Researcher3\", researcher3_node)\n",
    "workflow.add_node(\"Researcher4\", researcher4_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)\n",
    "\n",
    "\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\") \n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END \n",
    "\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%{init: {'flowchart': {'curve': 'linear'}}}%%\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tResearcher1(Researcher1)\n",
      "\tResearcher2(Researcher2)\n",
      "\tResearcher3(Researcher3)\n",
      "\tResearcher4(Researcher4)\n",
      "\tsupervisor(supervisor)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\tResearcher1 --> supervisor;\n",
      "\tResearcher2 --> supervisor;\n",
      "\tResearcher3 --> supervisor;\n",
      "\tResearcher4 --> supervisor;\n",
      "\t__start__ --> supervisor;\n",
      "\tsupervisor -.-> Researcher1;\n",
      "\tsupervisor -.-> Researcher2;\n",
      "\tsupervisor -.-> Researcher3;\n",
      "\tsupervisor -.-> Researcher4;\n",
      "\tsupervisor -. &nbsp;FINISH&nbsp; .-> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# graph.get_graph().draw_mermaid_png(output_file_path=\"./multiagentragtext_graph.png\")\n",
    "print(graph.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어쨋든 평가를 해야 할 요소는 RAG의 결과 즉, 데이터를 정확히 추출했냐면, \n",
    "굳이 문장으로 뽑지 않고 데이터를 csv 형태로 구축한 후 각 열 별로 평가하는 것이 좋지 않을까\n",
    "text를 값으로 받는 열의 경우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voltai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
